% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spark_context_config.R
\name{spark_session_config}
\alias{spark_session_config}
\title{Runtime configuration interface for the Spark Session}
\usage{
spark_session_config(sc, config = TRUE, value = NULL)
}
\arguments{
\item{sc}{A \code{spark_connection}.}

\item{config}{The configuration entry name(s) (e.g., \code{"spark.sql.shuffle.partitions"}).
Defaults to \code{NULL} to retrieve all configuration entries.}

\item{value}{The configuration value to be set. Defaults to \code{NULL} to retrieve
configuration entries.}
}
\description{
Retrieves or sets runtime configuration entries for the Spark Session
}
\seealso{
Other Spark runtime configuration: 
\code{\link{spark_adaptive_query_execution}()},
\code{\link{spark_advisory_shuffle_partition_size}()},
\code{\link{spark_auto_broadcast_join_threshold}()},
\code{\link{spark_coalesce_initial_num_partitions}()},
\code{\link{spark_coalesce_min_num_partitions}()},
\code{\link{spark_coalesce_shuffle_partitions}()}
}
\concept{Spark runtime configuration}
