17/09/21 17:51:57 INFO SparkContext: Running Spark version 2.1.0
17/09/21 17:51:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 17:51:58 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 17:51:58 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 17:51:58 INFO SecurityManager: Changing view acls groups to: 
17/09/21 17:51:58 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 17:51:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 17:51:58 INFO Utils: Successfully started service 'sparkDriver' on port 56995.
17/09/21 17:51:58 INFO SparkEnv: Registering MapOutputTracker
17/09/21 17:51:58 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 17:51:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 17:51:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 17:51:58 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-ad01620d-c60c-442b-a790-d78e2e099e1b
17/09/21 17:51:58 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 17:51:58 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 17:51:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 17:51:58 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 17:51:58 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 17:51:58 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:56995/jars/sparklyr-2.1-2.11.jar with timestamp 1506041518666
17/09/21 17:51:58 INFO Executor: Starting executor ID driver on host localhost
17/09/21 17:51:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56996.
17/09/21 17:51:58 INFO NettyBlockTransferService: Server created on 127.0.0.1:56996
17/09/21 17:51:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 17:51:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56996, None)
17/09/21 17:51:58 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56996 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 56996, None)
17/09/21 17:51:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56996, None)
17/09/21 17:51:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56996, None)
17/09/21 17:51:58 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 17:51:58 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 17:51:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 17:51:58 INFO MemoryStore: MemoryStore cleared
17/09/21 17:51:58 INFO BlockManager: BlockManager stopped
17/09/21 17:51:59 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 17:51:59 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 17:51:59 INFO SparkContext: Successfully stopped SparkContext
17/09/21 17:51:59 INFO ShutdownHookManager: Shutdown hook called
17/09/21 17:51:59 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-86fc8ab4-82f6-4517-8f70-3deb8df5b2f8
17/09/21 17:53:05 INFO RSCDriver: Connecting to: 10.0.1.18:57084
17/09/21 17:53:05 INFO RSCDriver: Starting RPC server...
17/09/21 17:53:10 WARN RSCConf: Your hostname, 10.0.1.18, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 17:53:10 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 17:53:10 INFO RSCDriver: Received job request 632ef190-4d38-4b56-8f70-64de35359960
17/09/21 17:53:10 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 17:53:13 INFO SparkContext: Running Spark version 2.1.0
17/09/21 17:53:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 17:53:19 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 17:53:19 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 17:53:19 INFO SecurityManager: Changing view acls groups to: 
17/09/21 17:53:19 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 17:53:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 17:53:19 INFO Utils: Successfully started service 'sparkDriver' on port 57091.
17/09/21 17:53:19 INFO SparkEnv: Registering MapOutputTracker
17/09/21 17:53:19 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 17:53:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 17:53:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 17:53:19 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-991fa03a-0086-4b38-a117-b7228716584c
17/09/21 17:53:19 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 17:53:19 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 17:53:19 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 17:53:19 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.1.18:4040
17/09/21 17:53:19 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://10.0.1.18:57091/jars/livy-api-0.3.0.jar with timestamp 1506041599522
17/09/21 17:53:19 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://10.0.1.18:57091/jars/livy-rsc-0.3.0.jar with timestamp 1506041599523
17/09/21 17:53:19 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://10.0.1.18:57091/jars/netty-all-4.0.29.Final.jar with timestamp 1506041599523
17/09/21 17:53:19 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://10.0.1.18:57091/jars/commons-codec-1.9.jar with timestamp 1506041599524
17/09/21 17:53:19 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://10.0.1.18:57091/jars/livy-core_2.11-0.3.0.jar with timestamp 1506041599524
17/09/21 17:53:19 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://10.0.1.18:57091/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506041599524
17/09/21 17:53:19 INFO Executor: Starting executor ID driver on host localhost
17/09/21 17:53:19 INFO Executor: Using REPL class URI: spark://10.0.1.18:57091/classes
17/09/21 17:53:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57092.
17/09/21 17:53:19 INFO NettyBlockTransferService: Server created on 10.0.1.18:57092
17/09/21 17:53:19 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 17:53:19 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.1.18, 57092, None)
17/09/21 17:53:19 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.1.18:57092 with 366.3 MB RAM, BlockManagerId(driver, 10.0.1.18, 57092, None)
17/09/21 17:53:19 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.1.18, 57092, None)
17/09/21 17:53:19 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.1.18, 57092, None)
17/09/21 17:53:19 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse'.
17/09/21 17:53:20 INFO SparkInterpreter: Created Spark session.
17/09/21 17:54:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 17:54:10 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 17:54:19 INFO CodeGenerator: Code generated in 179.567858 ms
17/09/21 17:54:19 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 17:54:19 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 17:54:19 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 17:54:19 INFO DAGScheduler: Parents of final stage: List()
17/09/21 17:54:19 INFO DAGScheduler: Missing parents: List()
17/09/21 17:54:19 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 17:54:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 17:54:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 17:54:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.1.18:57092 (size: 4.6 KB, free: 366.3 MB)
17/09/21 17:54:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 17:54:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 17:54:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 17:54:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6462 bytes)
17/09/21 17:54:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 17:54:19 INFO Executor: Fetching spark://10.0.1.18:57091/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506041599524
17/09/21 17:54:19 INFO TransportClientFactory: Successfully created connection to /10.0.1.18:57091 after 8 ms (0 ms spent in bootstraps)
17/09/21 17:54:19 INFO Utils: Fetching spark://10.0.1.18:57091/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/fetchFileTemp4972731169091059424.tmp
17/09/21 17:54:19 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 17:54:19 INFO Executor: Fetching spark://10.0.1.18:57091/jars/livy-core_2.11-0.3.0.jar with timestamp 1506041599524
17/09/21 17:54:19 INFO Utils: Fetching spark://10.0.1.18:57091/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/fetchFileTemp7293044209535905467.tmp
17/09/21 17:54:19 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/livy-core_2.11-0.3.0.jar to class loader
17/09/21 17:54:19 INFO Executor: Fetching spark://10.0.1.18:57091/jars/commons-codec-1.9.jar with timestamp 1506041599524
17/09/21 17:54:19 INFO Utils: Fetching spark://10.0.1.18:57091/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/fetchFileTemp873950993257841998.tmp
17/09/21 17:54:19 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/commons-codec-1.9.jar to class loader
17/09/21 17:54:19 INFO Executor: Fetching spark://10.0.1.18:57091/jars/livy-api-0.3.0.jar with timestamp 1506041599522
17/09/21 17:54:19 INFO Utils: Fetching spark://10.0.1.18:57091/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/fetchFileTemp463120245064352669.tmp
17/09/21 17:54:19 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/livy-api-0.3.0.jar to class loader
17/09/21 17:54:19 INFO Executor: Fetching spark://10.0.1.18:57091/jars/netty-all-4.0.29.Final.jar with timestamp 1506041599523
17/09/21 17:54:19 INFO Utils: Fetching spark://10.0.1.18:57091/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/fetchFileTemp1366693102133326744.tmp
17/09/21 17:54:19 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/netty-all-4.0.29.Final.jar to class loader
17/09/21 17:54:19 INFO Executor: Fetching spark://10.0.1.18:57091/jars/livy-rsc-0.3.0.jar with timestamp 1506041599523
17/09/21 17:54:19 INFO Utils: Fetching spark://10.0.1.18:57091/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/fetchFileTemp8613429752892761635.tmp
17/09/21 17:54:19 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4/userFiles-e06c8802-d324-4900-946d-7abe8a001234/livy-rsc-0.3.0.jar to class loader
17/09/21 17:54:19 INFO CodeGenerator: Code generated in 18.183869 ms
17/09/21 17:54:19 INFO CodeGenerator: Code generated in 12.674119 ms
17/09/21 17:54:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/09/21 17:54:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 653 ms on localhost (executor driver) (1/1)
17/09/21 17:54:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 17:54:20 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.666 s
17/09/21 17:54:20 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.825576 s
17/09/21 17:54:26 INFO SparkSqlParser: Parsing command: df
17/09/21 17:54:28 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 17:54:28 INFO SparkSqlParser: Parsing command: `df`
17/09/21 17:54:28 INFO CodeGenerator: Code generated in 14.5957 ms
17/09/21 17:54:28 INFO CodeGenerator: Code generated in 11.686808 ms
17/09/21 17:54:28 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 17:54:28 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 17:54:28 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 17:54:28 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 17:54:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 17:54:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 17:54:28 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 17:54:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 17:54:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 17:54:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.1.18:57092 (size: 7.6 KB, free: 366.3 MB)
17/09/21 17:54:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 17:54:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 17:54:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 17:54:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6686 bytes)
17/09/21 17:54:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 17:54:28 INFO CodeGenerator: Code generated in 12.31334 ms
17/09/21 17:54:28 INFO CodeGenerator: Code generated in 42.250817 ms
17/09/21 17:54:28 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 17:54:28 INFO BlockManagerInfo: Added rdd_10_0 in memory on 10.0.1.18:57092 (size: 464.0 B, free: 366.3 MB)
17/09/21 17:54:28 INFO CodeGenerator: Code generated in 7.830766 ms
17/09/21 17:54:28 INFO CodeGenerator: Code generated in 20.330445 ms
17/09/21 17:54:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2747 bytes result sent to driver
17/09/21 17:54:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 186 ms on localhost (executor driver) (1/1)
17/09/21 17:54:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 17:54:28 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.187 s
17/09/21 17:54:28 INFO DAGScheduler: looking for newly runnable stages
17/09/21 17:54:28 INFO DAGScheduler: running: Set()
17/09/21 17:54:28 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 17:54:28 INFO DAGScheduler: failed: Set()
17/09/21 17:54:28 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 17:54:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 17:54:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 17:54:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.1.18:57092 (size: 3.7 KB, free: 366.3 MB)
17/09/21 17:54:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 17:54:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 17:54:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 17:54:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6374 bytes)
17/09/21 17:54:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 17:54:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 17:54:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/09/21 17:54:28 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/09/21 17:54:28 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1)
17/09/21 17:54:28 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 17:54:28 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.032 s
17/09/21 17:54:28 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.254149 s
17/09/21 17:54:28 INFO CodeGenerator: Code generated in 13.784521 ms
17/09/21 17:54:28 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 17:54:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.1.18:57092 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 17:54:28 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.1.18:57092 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 17:54:30 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 17:54:31 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 17:54:31 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 17:54:31 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 17:54:31 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 17:54:31 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 17:54:31 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 17:54:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 17:54:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 17:54:31 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 17:54:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 17:54:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 17:54:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.1.18:57092 (size: 7.6 KB, free: 366.3 MB)
17/09/21 17:54:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 17:54:31 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 17:54:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 17:54:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6678 bytes)
17/09/21 17:54:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 17:54:31 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 17:54:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2098 bytes result sent to driver
17/09/21 17:54:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 11 ms on localhost (executor driver) (1/1)
17/09/21 17:54:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 17:54:31 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.012 s
17/09/21 17:54:31 INFO DAGScheduler: looking for newly runnable stages
17/09/21 17:54:31 INFO DAGScheduler: running: Set()
17/09/21 17:54:31 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 17:54:31 INFO DAGScheduler: failed: Set()
17/09/21 17:54:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 17:54:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 17:54:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 17:54:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.1.18:57092 (size: 3.7 KB, free: 366.3 MB)
17/09/21 17:54:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 17:54:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 17:54:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 17:54:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6366 bytes)
17/09/21 17:54:31 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 17:54:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 17:54:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/09/21 17:54:31 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2129 bytes result sent to driver
17/09/21 17:54:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
17/09/21 17:54:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 17:54:31 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 17:54:31 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.029539 s
17/09/21 17:54:32 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 17:54:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.1.18:57092 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 17:54:32 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.1.18:57092 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 17:54:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 17:54:34 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 17:54:35 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 17:54:35 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 17:54:35 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 17:54:35 INFO DAGScheduler: Parents of final stage: List()
17/09/21 17:54:35 INFO DAGScheduler: Missing parents: List()
17/09/21 17:54:35 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 17:54:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 17:54:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 17:54:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.1.18:57092 (size: 5.7 KB, free: 366.3 MB)
17/09/21 17:54:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 17:54:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 17:54:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 17:54:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6689 bytes)
17/09/21 17:54:35 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 17:54:35 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 17:54:35 INFO CodeGenerator: Code generated in 20.646206 ms
17/09/21 17:54:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1608 bytes result sent to driver
17/09/21 17:54:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (executor driver) (1/1)
17/09/21 17:54:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 17:54:35 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.034 s
17/09/21 17:54:35 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.038894 s
17/09/21 17:54:35 INFO CodeGenerator: Code generated in 7.765137 ms
17/09/21 17:54:36 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.1.18:57092 in memory (size: 5.7 KB, free: 366.3 MB)
17/09/21 17:54:36 INFO SparkUI: Stopped Spark web UI at http://10.0.1.18:4040
17/09/21 17:54:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 17:54:36 INFO MemoryStore: MemoryStore cleared
17/09/21 17:54:36 INFO BlockManager: BlockManager stopped
17/09/21 17:54:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 17:54:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 17:54:36 INFO SparkContext: Successfully stopped SparkContext
17/09/21 17:54:36 INFO SparkContext: SparkContext already stopped.
17/09/21 17:54:36 INFO ShutdownHookManager: Shutdown hook called
17/09/21 17:54:36 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-937f4ae4-e17e-4270-a346-fce8c0df72d4
17/09/21 22:07:03 INFO SparkContext: Running Spark version 2.1.0
17/09/21 22:07:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 22:07:04 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 22:07:04 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 22:07:04 INFO SecurityManager: Changing view acls groups to: 
17/09/21 22:07:04 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 22:07:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 22:07:04 INFO Utils: Successfully started service 'sparkDriver' on port 59369.
17/09/21 22:07:04 INFO SparkEnv: Registering MapOutputTracker
17/09/21 22:07:04 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 22:07:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 22:07:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 22:07:04 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-01ee5a9c-405b-4255-b563-b115cf0775e8
17/09/21 22:07:04 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 22:07:04 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 22:07:04 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 22:07:04 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 22:07:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 22:07:04 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:59369/jars/sparklyr-2.1-2.11.jar with timestamp 1506056824767
17/09/21 22:07:04 INFO Executor: Starting executor ID driver on host localhost
17/09/21 22:07:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59370.
17/09/21 22:07:04 INFO NettyBlockTransferService: Server created on 127.0.0.1:59370
17/09/21 22:07:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 22:07:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 59370, None)
17/09/21 22:07:04 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:59370 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 59370, None)
17/09/21 22:07:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 59370, None)
17/09/21 22:07:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 59370, None)
17/09/21 22:07:04 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 22:07:05 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 22:07:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 22:07:05 INFO MemoryStore: MemoryStore cleared
17/09/21 22:07:05 INFO BlockManager: BlockManager stopped
17/09/21 22:07:05 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 22:07:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 22:07:05 INFO SparkContext: Successfully stopped SparkContext
17/09/21 22:07:05 INFO ShutdownHookManager: Shutdown hook called
17/09/21 22:07:05 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-68eefed5-22cf-4aea-bf87-3be5425194b0
17/09/21 22:08:02 INFO RSCDriver: Connecting to: 192.168.0.22:59498
17/09/21 22:08:02 INFO RSCDriver: Starting RPC server...
17/09/21 22:08:07 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 22:08:07 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 22:08:07 INFO RSCDriver: Received job request 7b6ff280-58d9-4fc0-8133-47c61944adf3
17/09/21 22:08:07 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 22:08:10 INFO SparkContext: Running Spark version 2.1.0
17/09/21 22:08:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 22:08:15 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 22:08:15 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 22:08:15 INFO SecurityManager: Changing view acls groups to: 
17/09/21 22:08:15 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 22:08:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 22:08:15 INFO Utils: Successfully started service 'sparkDriver' on port 59503.
17/09/21 22:08:15 INFO SparkEnv: Registering MapOutputTracker
17/09/21 22:08:15 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 22:08:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 22:08:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 22:08:15 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-488fa8c0-0fec-4279-8e4e-12d52dce5acd
17/09/21 22:08:15 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 22:08:15 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 22:08:15 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 22:08:15 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 22:08:15 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:59503/jars/livy-api-0.3.0.jar with timestamp 1506056895874
17/09/21 22:08:15 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:59503/jars/livy-rsc-0.3.0.jar with timestamp 1506056895875
17/09/21 22:08:15 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:59503/jars/netty-all-4.0.29.Final.jar with timestamp 1506056895875
17/09/21 22:08:15 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:59503/jars/commons-codec-1.9.jar with timestamp 1506056895875
17/09/21 22:08:15 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:59503/jars/livy-core_2.11-0.3.0.jar with timestamp 1506056895875
17/09/21 22:08:15 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:59503/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506056895876
17/09/21 22:08:15 INFO Executor: Starting executor ID driver on host localhost
17/09/21 22:08:15 INFO Executor: Using REPL class URI: spark://192.168.0.22:59503/classes
17/09/21 22:08:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59504.
17/09/21 22:08:15 INFO NettyBlockTransferService: Server created on 192.168.0.22:59504
17/09/21 22:08:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 22:08:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 59504, None)
17/09/21 22:08:15 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:59504 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 59504, None)
17/09/21 22:08:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 59504, None)
17/09/21 22:08:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 59504, None)
17/09/21 22:08:16 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 22:08:16 INFO SparkInterpreter: Created Spark session.
17/09/21 22:09:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 22:09:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 22:09:15 INFO CodeGenerator: Code generated in 174.951916 ms
17/09/21 22:09:15 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 22:09:15 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 22:09:15 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 22:09:15 INFO DAGScheduler: Parents of final stage: List()
17/09/21 22:09:15 INFO DAGScheduler: Missing parents: List()
17/09/21 22:09:15 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 22:09:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 22:09:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 22:09:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:59504 (size: 4.6 KB, free: 366.3 MB)
17/09/21 22:09:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 22:09:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 22:09:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 22:09:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 22:09:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 22:09:15 INFO Executor: Fetching spark://192.168.0.22:59503/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506056895876
17/09/21 22:09:16 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:59503 after 7 ms (0 ms spent in bootstraps)
17/09/21 22:09:16 INFO Utils: Fetching spark://192.168.0.22:59503/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/fetchFileTemp6364830232252501903.tmp
17/09/21 22:09:16 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 22:09:16 INFO Executor: Fetching spark://192.168.0.22:59503/jars/netty-all-4.0.29.Final.jar with timestamp 1506056895875
17/09/21 22:09:16 INFO Utils: Fetching spark://192.168.0.22:59503/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/fetchFileTemp4341328085775590057.tmp
17/09/21 22:09:16 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/netty-all-4.0.29.Final.jar to class loader
17/09/21 22:09:16 INFO Executor: Fetching spark://192.168.0.22:59503/jars/livy-core_2.11-0.3.0.jar with timestamp 1506056895875
17/09/21 22:09:16 INFO Utils: Fetching spark://192.168.0.22:59503/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/fetchFileTemp656858088340452112.tmp
17/09/21 22:09:16 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/livy-core_2.11-0.3.0.jar to class loader
17/09/21 22:09:16 INFO Executor: Fetching spark://192.168.0.22:59503/jars/livy-api-0.3.0.jar with timestamp 1506056895874
17/09/21 22:09:16 INFO Utils: Fetching spark://192.168.0.22:59503/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/fetchFileTemp1271885093835944017.tmp
17/09/21 22:09:16 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/livy-api-0.3.0.jar to class loader
17/09/21 22:09:16 INFO Executor: Fetching spark://192.168.0.22:59503/jars/livy-rsc-0.3.0.jar with timestamp 1506056895875
17/09/21 22:09:16 INFO Utils: Fetching spark://192.168.0.22:59503/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/fetchFileTemp1345831415685241597.tmp
17/09/21 22:09:16 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/livy-rsc-0.3.0.jar to class loader
17/09/21 22:09:16 INFO Executor: Fetching spark://192.168.0.22:59503/jars/commons-codec-1.9.jar with timestamp 1506056895875
17/09/21 22:09:16 INFO Utils: Fetching spark://192.168.0.22:59503/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/fetchFileTemp3834425026331174727.tmp
17/09/21 22:09:16 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856/userFiles-afd60c4f-6e15-488a-a7b2-561e67a28bbb/commons-codec-1.9.jar to class loader
17/09/21 22:09:16 INFO CodeGenerator: Code generated in 17.97021 ms
17/09/21 22:09:16 INFO CodeGenerator: Code generated in 13.529201 ms
17/09/21 22:09:16 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1391 bytes result sent to driver
17/09/21 22:09:16 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 574 ms on localhost (executor driver) (1/1)
17/09/21 22:09:16 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 22:09:16 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.588 s
17/09/21 22:09:16 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.738954 s
17/09/21 22:09:23 INFO SparkSqlParser: Parsing command: df
17/09/21 22:09:24 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 22:09:24 INFO SparkSqlParser: Parsing command: `df`
17/09/21 22:09:24 INFO CodeGenerator: Code generated in 15.579111 ms
17/09/21 22:09:24 INFO CodeGenerator: Code generated in 11.370382 ms
17/09/21 22:09:24 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 22:09:24 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:09:24 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 22:09:24 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:09:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 22:09:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 22:09:24 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 22:09:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 22:09:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 22:09:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:59504 (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:09:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 22:09:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:09:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 22:09:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 22:09:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 22:09:24 INFO CodeGenerator: Code generated in 11.233547 ms
17/09/21 22:09:25 INFO CodeGenerator: Code generated in 41.47594 ms
17/09/21 22:09:25 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 22:09:25 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:59504 (size: 464.0 B, free: 366.3 MB)
17/09/21 22:09:25 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 22:09:25 INFO CodeGenerator: Code generated in 6.506935 ms
17/09/21 22:09:25 INFO CodeGenerator: Code generated in 19.475596 ms
17/09/21 22:09:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2823 bytes result sent to driver
17/09/21 22:09:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 180 ms on localhost (executor driver) (1/1)
17/09/21 22:09:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 22:09:25 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.181 s
17/09/21 22:09:25 INFO DAGScheduler: looking for newly runnable stages
17/09/21 22:09:25 INFO DAGScheduler: running: Set()
17/09/21 22:09:25 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 22:09:25 INFO DAGScheduler: failed: Set()
17/09/21 22:09:25 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 22:09:25 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 22:09:25 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 22:09:25 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:59504 (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:09:25 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 22:09:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:09:25 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 22:09:25 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 22:09:25 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 22:09:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 22:09:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/09/21 22:09:25 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/09/21 22:09:25 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
17/09/21 22:09:25 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 22:09:25 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.029 s
17/09/21 22:09:25 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.245235 s
17/09/21 22:09:25 INFO CodeGenerator: Code generated in 8.198654 ms
17/09/21 22:09:26 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 22:09:27 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:59504 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 22:09:27 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 22:09:27 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 22:09:27 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:59504 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:09:28 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 22:09:28 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 22:09:28 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 22:09:28 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 22:09:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 22:09:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 22:09:28 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 22:09:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 22:09:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 22:09:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:59504 (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:09:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 22:09:28 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 22:09:28 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 22:09:28 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 22:09:28 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 22:09:28 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 22:09:28 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 22:09:28 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 13 ms on localhost (executor driver) (1/1)
17/09/21 22:09:28 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 22:09:28 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.013 s
17/09/21 22:09:28 INFO DAGScheduler: looking for newly runnable stages
17/09/21 22:09:28 INFO DAGScheduler: running: Set()
17/09/21 22:09:28 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 22:09:28 INFO DAGScheduler: failed: Set()
17/09/21 22:09:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 22:09:28 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 22:09:28 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 22:09:28 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:59504 (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:09:28 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 22:09:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 22:09:28 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 22:09:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 22:09:28 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 22:09:28 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 22:09:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/21 22:09:28 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 22:09:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
17/09/21 22:09:28 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 22:09:28 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 22:09:28 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.032696 s
17/09/21 22:09:29 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 22:09:29 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:59504 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:09:29 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:59504 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:09:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 22:09:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 22:09:32 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 22:09:32 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 22:09:32 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 22:09:32 INFO DAGScheduler: Parents of final stage: List()
17/09/21 22:09:32 INFO DAGScheduler: Missing parents: List()
17/09/21 22:09:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 22:09:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 22:09:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 22:09:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:59504 (size: 5.7 KB, free: 366.3 MB)
17/09/21 22:09:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 22:09:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 22:09:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 22:09:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 22:09:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 22:09:32 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 22:09:32 INFO CodeGenerator: Code generated in 20.557537 ms
17/09/21 22:09:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1521 bytes result sent to driver
17/09/21 22:09:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (executor driver) (1/1)
17/09/21 22:09:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 22:09:32 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.033 s
17/09/21 22:09:32 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.038566 s
17/09/21 22:09:32 INFO CodeGenerator: Code generated in 7.665041 ms
17/09/21 22:09:33 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 22:09:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 22:09:33 INFO MemoryStore: MemoryStore cleared
17/09/21 22:09:33 INFO BlockManager: BlockManager stopped
17/09/21 22:09:33 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 22:09:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 22:09:33 INFO SparkContext: Successfully stopped SparkContext
17/09/21 22:09:33 INFO SparkContext: SparkContext already stopped.
17/09/21 22:09:33 INFO ShutdownHookManager: Shutdown hook called
17/09/21 22:09:33 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-9e2819dd-e09f-44e0-9c23-0aab73db1856
17/09/21 22:15:59 INFO SparkContext: Running Spark version 2.1.0
17/09/21 22:15:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 22:15:59 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 22:15:59 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 22:15:59 INFO SecurityManager: Changing view acls groups to: 
17/09/21 22:15:59 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 22:15:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 22:15:59 INFO Utils: Successfully started service 'sparkDriver' on port 60153.
17/09/21 22:16:00 INFO SparkEnv: Registering MapOutputTracker
17/09/21 22:16:00 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 22:16:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 22:16:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 22:16:00 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-36567a48-42cc-4c67-9c2b-2d50012d1f3f
17/09/21 22:16:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 22:16:00 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 22:16:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 22:16:00 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 22:16:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 22:16:00 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:60153/jars/sparklyr-2.1-2.11.jar with timestamp 1506057360299
17/09/21 22:16:00 INFO Executor: Starting executor ID driver on host localhost
17/09/21 22:16:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60154.
17/09/21 22:16:00 INFO NettyBlockTransferService: Server created on 127.0.0.1:60154
17/09/21 22:16:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 22:16:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60154, None)
17/09/21 22:16:00 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60154 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60154, None)
17/09/21 22:16:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60154, None)
17/09/21 22:16:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60154, None)
17/09/21 22:16:00 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 22:16:00 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 22:16:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 22:16:00 INFO MemoryStore: MemoryStore cleared
17/09/21 22:16:00 INFO BlockManager: BlockManager stopped
17/09/21 22:16:00 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 22:16:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 22:16:00 INFO SparkContext: Successfully stopped SparkContext
17/09/21 22:16:00 INFO ShutdownHookManager: Shutdown hook called
17/09/21 22:16:00 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-58585804-d51e-4d7a-8f83-9f2b7b17b29c
17/09/21 22:16:57 INFO RSCDriver: Connecting to: 192.168.0.22:60282
17/09/21 22:16:57 INFO RSCDriver: Starting RPC server...
17/09/21 22:17:02 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 22:17:02 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 22:17:03 INFO RSCDriver: Received job request 65f24f15-8747-48c7-acbc-d3d5be307d4a
17/09/21 22:17:03 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 22:17:05 INFO SparkContext: Running Spark version 2.1.0
17/09/21 22:17:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 22:17:10 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 22:17:10 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 22:17:10 INFO SecurityManager: Changing view acls groups to: 
17/09/21 22:17:10 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 22:17:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 22:17:10 INFO Utils: Successfully started service 'sparkDriver' on port 60286.
17/09/21 22:17:10 INFO SparkEnv: Registering MapOutputTracker
17/09/21 22:17:10 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 22:17:10 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 22:17:10 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 22:17:10 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-e6087b43-2c44-4d77-82d2-ca2a5873283c
17/09/21 22:17:10 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 22:17:11 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 22:17:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 22:17:11 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 22:17:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:60286/jars/livy-api-0.3.0.jar with timestamp 1506057431288
17/09/21 22:17:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:60286/jars/livy-rsc-0.3.0.jar with timestamp 1506057431289
17/09/21 22:17:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:60286/jars/netty-all-4.0.29.Final.jar with timestamp 1506057431289
17/09/21 22:17:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:60286/jars/commons-codec-1.9.jar with timestamp 1506057431289
17/09/21 22:17:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:60286/jars/livy-core_2.11-0.3.0.jar with timestamp 1506057431289
17/09/21 22:17:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:60286/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506057431290
17/09/21 22:17:11 INFO Executor: Starting executor ID driver on host localhost
17/09/21 22:17:11 INFO Executor: Using REPL class URI: spark://192.168.0.22:60286/classes
17/09/21 22:17:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60287.
17/09/21 22:17:11 INFO NettyBlockTransferService: Server created on 192.168.0.22:60287
17/09/21 22:17:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 22:17:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 60287, None)
17/09/21 22:17:11 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:60287 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 60287, None)
17/09/21 22:17:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 60287, None)
17/09/21 22:17:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 60287, None)
17/09/21 22:17:11 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 22:17:11 INFO SparkInterpreter: Created Spark session.
17/09/21 22:18:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 22:18:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 22:18:14 INFO CodeGenerator: Code generated in 170.95738 ms
17/09/21 22:18:14 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 22:18:14 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 22:18:14 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 22:18:14 INFO DAGScheduler: Parents of final stage: List()
17/09/21 22:18:14 INFO DAGScheduler: Missing parents: List()
17/09/21 22:18:14 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 22:18:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 22:18:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 22:18:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:60287 (size: 4.6 KB, free: 366.3 MB)
17/09/21 22:18:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 22:18:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 22:18:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 22:18:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 22:18:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 22:18:14 INFO Executor: Fetching spark://192.168.0.22:60286/jars/livy-rsc-0.3.0.jar with timestamp 1506057431289
17/09/21 22:18:14 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:60286 after 7 ms (0 ms spent in bootstraps)
17/09/21 22:18:14 INFO Utils: Fetching spark://192.168.0.22:60286/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/fetchFileTemp3551700367670192881.tmp
17/09/21 22:18:14 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/livy-rsc-0.3.0.jar to class loader
17/09/21 22:18:14 INFO Executor: Fetching spark://192.168.0.22:60286/jars/commons-codec-1.9.jar with timestamp 1506057431289
17/09/21 22:18:14 INFO Utils: Fetching spark://192.168.0.22:60286/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/fetchFileTemp685234920257554532.tmp
17/09/21 22:18:14 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/commons-codec-1.9.jar to class loader
17/09/21 22:18:14 INFO Executor: Fetching spark://192.168.0.22:60286/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506057431290
17/09/21 22:18:14 INFO Utils: Fetching spark://192.168.0.22:60286/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/fetchFileTemp5180862837885158945.tmp
17/09/21 22:18:14 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 22:18:14 INFO Executor: Fetching spark://192.168.0.22:60286/jars/livy-core_2.11-0.3.0.jar with timestamp 1506057431289
17/09/21 22:18:14 INFO Utils: Fetching spark://192.168.0.22:60286/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/fetchFileTemp6775893990742830546.tmp
17/09/21 22:18:14 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/livy-core_2.11-0.3.0.jar to class loader
17/09/21 22:18:14 INFO Executor: Fetching spark://192.168.0.22:60286/jars/livy-api-0.3.0.jar with timestamp 1506057431288
17/09/21 22:18:14 INFO Utils: Fetching spark://192.168.0.22:60286/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/fetchFileTemp5415000320169887863.tmp
17/09/21 22:18:14 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/livy-api-0.3.0.jar to class loader
17/09/21 22:18:14 INFO Executor: Fetching spark://192.168.0.22:60286/jars/netty-all-4.0.29.Final.jar with timestamp 1506057431289
17/09/21 22:18:14 INFO Utils: Fetching spark://192.168.0.22:60286/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/fetchFileTemp6575736890565122860.tmp
17/09/21 22:18:14 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34/userFiles-e6e4a236-2f5d-44a1-8a9d-0e5cdfd876b6/netty-all-4.0.29.Final.jar to class loader
17/09/21 22:18:14 INFO CodeGenerator: Code generated in 16.591398 ms
17/09/21 22:18:14 INFO CodeGenerator: Code generated in 13.789533 ms
17/09/21 22:18:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/09/21 22:18:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 301 ms on localhost (executor driver) (1/1)
17/09/21 22:18:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 22:18:15 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.616 s
17/09/21 22:18:15 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.767137 s
17/09/21 22:18:22 INFO SparkSqlParser: Parsing command: df
17/09/21 22:18:23 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 22:18:23 INFO SparkSqlParser: Parsing command: `df`
17/09/21 22:18:23 INFO CodeGenerator: Code generated in 16.873291 ms
17/09/21 22:18:23 INFO CodeGenerator: Code generated in 12.856138 ms
17/09/21 22:18:23 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 22:18:23 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:18:23 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 22:18:23 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:18:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 22:18:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 22:18:23 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 22:18:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 22:18:23 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 22:18:23 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:60287 (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:18:23 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 22:18:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:18:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 22:18:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 22:18:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 22:18:23 INFO CodeGenerator: Code generated in 12.21461 ms
17/09/21 22:18:23 INFO CodeGenerator: Code generated in 42.302267 ms
17/09/21 22:18:23 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 22:18:23 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:60287 (size: 464.0 B, free: 366.3 MB)
17/09/21 22:18:23 INFO CodeGenerator: Code generated in 7.158081 ms
17/09/21 22:18:23 INFO CodeGenerator: Code generated in 20.24783 ms
17/09/21 22:18:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2750 bytes result sent to driver
17/09/21 22:18:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 180 ms on localhost (executor driver) (1/1)
17/09/21 22:18:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 22:18:23 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.182 s
17/09/21 22:18:23 INFO DAGScheduler: looking for newly runnable stages
17/09/21 22:18:23 INFO DAGScheduler: running: Set()
17/09/21 22:18:23 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 22:18:23 INFO DAGScheduler: failed: Set()
17/09/21 22:18:23 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 22:18:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 22:18:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 22:18:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:60287 (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:18:23 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 22:18:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 22:18:23 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 22:18:23 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 22:18:23 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 22:18:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 22:18:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/09/21 22:18:23 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 22:18:23 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2115 bytes result sent to driver
17/09/21 22:18:23 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 36 ms on localhost (executor driver) (1/1)
17/09/21 22:18:23 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 22:18:23 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.036 s
17/09/21 22:18:23 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.253638 s
17/09/21 22:18:23 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:60287 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:18:23 INFO CodeGenerator: Code generated in 8.313612 ms
17/09/21 22:18:25 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 22:18:26 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 22:18:26 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 22:18:26 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:60287 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:18:26 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 22:18:26 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 22:18:26 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 22:18:26 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 22:18:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 22:18:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 22:18:26 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 22:18:26 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 22:18:26 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 22:18:26 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:60287 (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:18:26 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 22:18:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 22:18:26 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 22:18:26 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 22:18:26 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 22:18:26 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 22:18:26 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 22:18:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 13 ms on localhost (executor driver) (1/1)
17/09/21 22:18:26 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 22:18:26 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.014 s
17/09/21 22:18:26 INFO DAGScheduler: looking for newly runnable stages
17/09/21 22:18:26 INFO DAGScheduler: running: Set()
17/09/21 22:18:26 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 22:18:26 INFO DAGScheduler: failed: Set()
17/09/21 22:18:26 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 22:18:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 22:18:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 22:18:26 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:60287 (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:18:26 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 22:18:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 22:18:26 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 22:18:26 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 22:18:26 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 22:18:26 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 22:18:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/21 22:18:26 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 22:18:26 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
17/09/21 22:18:26 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 22:18:26 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 22:18:26 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.032483 s
17/09/21 22:18:27 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:60287 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 22:18:27 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 22:18:27 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:60287 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 22:18:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 22:18:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 22:18:31 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 22:18:31 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 22:18:31 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 22:18:31 INFO DAGScheduler: Parents of final stage: List()
17/09/21 22:18:31 INFO DAGScheduler: Missing parents: List()
17/09/21 22:18:31 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 22:18:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 22:18:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 22:18:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:60287 (size: 5.7 KB, free: 366.3 MB)
17/09/21 22:18:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 22:18:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 22:18:31 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 22:18:31 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 22:18:31 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 22:18:31 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 22:18:31 INFO CodeGenerator: Code generated in 18.687268 ms
17/09/21 22:18:31 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1521 bytes result sent to driver
17/09/21 22:18:31 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on localhost (executor driver) (1/1)
17/09/21 22:18:31 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 22:18:31 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.032 s
17/09/21 22:18:31 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.037050 s
17/09/21 22:18:31 INFO CodeGenerator: Code generated in 8.394434 ms
17/09/21 22:18:32 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 22:18:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 22:18:32 INFO MemoryStore: MemoryStore cleared
17/09/21 22:18:32 INFO BlockManager: BlockManager stopped
17/09/21 22:18:32 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 22:18:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 22:18:32 INFO SparkContext: Successfully stopped SparkContext
17/09/21 22:18:32 INFO SparkContext: SparkContext already stopped.
17/09/21 22:18:32 INFO ShutdownHookManager: Shutdown hook called
17/09/21 22:18:32 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0ae730f9-b9e3-4a30-996e-151284095f34
17/09/21 23:00:19 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:00:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:00:19 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:00:19 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:00:19 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:00:19 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:00:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:00:19 INFO Utils: Successfully started service 'sparkDriver' on port 61677.
17/09/21 23:00:19 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:00:19 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:00:19 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:00:19 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:00:19 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-1b1c85d8-7006-4343-8c95-69cbe9bb1d87
17/09/21 23:00:19 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:00:19 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:00:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 23:00:19 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 23:00:19 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 23:00:19 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:61677/jars/sparklyr-2.1-2.11.jar with timestamp 1506060019965
17/09/21 23:00:20 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:00:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61678.
17/09/21 23:00:20 INFO NettyBlockTransferService: Server created on 127.0.0.1:61678
17/09/21 23:00:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:00:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61678, None)
17/09/21 23:00:20 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61678 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61678, None)
17/09/21 23:00:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61678, None)
17/09/21 23:00:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61678, None)
17/09/21 23:00:20 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 23:00:20 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 23:00:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:00:20 INFO MemoryStore: MemoryStore cleared
17/09/21 23:00:20 INFO BlockManager: BlockManager stopped
17/09/21 23:00:20 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:00:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:00:20 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:00:20 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:00:20 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8a42352a-ed7c-4efa-b8c8-1e5a6e215c15
17/09/21 23:01:18 INFO RSCDriver: Connecting to: 192.168.0.22:61805
17/09/21 23:01:18 INFO RSCDriver: Starting RPC server...
17/09/21 23:01:23 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 23:01:23 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 23:01:23 INFO RSCDriver: Received job request 2e3d1ac8-99b5-43cf-bfe1-3839d697f750
17/09/21 23:01:23 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 23:01:25 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:01:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:01:31 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:01:31 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:01:31 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:01:31 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:01:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:01:31 INFO Utils: Successfully started service 'sparkDriver' on port 61810.
17/09/21 23:01:31 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:01:31 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:01:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:01:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:01:31 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-3ebafdea-fa97-4022-9c74-37f3c1b84234
17/09/21 23:01:31 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:01:31 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:01:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 23:01:31 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 23:01:31 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:61810/jars/livy-api-0.3.0.jar with timestamp 1506060091670
17/09/21 23:01:31 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:61810/jars/livy-rsc-0.3.0.jar with timestamp 1506060091671
17/09/21 23:01:31 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:61810/jars/netty-all-4.0.29.Final.jar with timestamp 1506060091671
17/09/21 23:01:31 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:61810/jars/commons-codec-1.9.jar with timestamp 1506060091671
17/09/21 23:01:31 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:61810/jars/livy-core_2.11-0.3.0.jar with timestamp 1506060091671
17/09/21 23:01:31 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:61810/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506060091672
17/09/21 23:01:31 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:01:31 INFO Executor: Using REPL class URI: spark://192.168.0.22:61810/classes
17/09/21 23:01:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61811.
17/09/21 23:01:31 INFO NettyBlockTransferService: Server created on 192.168.0.22:61811
17/09/21 23:01:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:01:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 61811, None)
17/09/21 23:01:31 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:61811 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 61811, None)
17/09/21 23:01:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 61811, None)
17/09/21 23:01:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 61811, None)
17/09/21 23:01:31 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 23:01:32 INFO SparkInterpreter: Created Spark session.
17/09/21 23:02:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 23:02:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 23:02:31 INFO CodeGenerator: Code generated in 173.27177 ms
17/09/21 23:02:31 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 23:02:31 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 23:02:31 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 23:02:31 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:02:31 INFO DAGScheduler: Missing parents: List()
17/09/21 23:02:31 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 23:02:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 23:02:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 23:02:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:61811 (size: 4.6 KB, free: 366.3 MB)
17/09/21 23:02:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 23:02:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 23:02:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 23:02:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 23:02:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 23:02:31 INFO Executor: Fetching spark://192.168.0.22:61810/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506060091672
17/09/21 23:02:31 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:61810 after 9 ms (0 ms spent in bootstraps)
17/09/21 23:02:31 INFO Utils: Fetching spark://192.168.0.22:61810/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/fetchFileTemp3801541787128123091.tmp
17/09/21 23:02:31 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 23:02:31 INFO Executor: Fetching spark://192.168.0.22:61810/jars/livy-api-0.3.0.jar with timestamp 1506060091670
17/09/21 23:02:31 INFO Utils: Fetching spark://192.168.0.22:61810/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/fetchFileTemp3572156251415803812.tmp
17/09/21 23:02:31 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/livy-api-0.3.0.jar to class loader
17/09/21 23:02:31 INFO Executor: Fetching spark://192.168.0.22:61810/jars/commons-codec-1.9.jar with timestamp 1506060091671
17/09/21 23:02:31 INFO Utils: Fetching spark://192.168.0.22:61810/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/fetchFileTemp3483531852295243091.tmp
17/09/21 23:02:31 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/commons-codec-1.9.jar to class loader
17/09/21 23:02:31 INFO Executor: Fetching spark://192.168.0.22:61810/jars/livy-core_2.11-0.3.0.jar with timestamp 1506060091671
17/09/21 23:02:31 INFO Utils: Fetching spark://192.168.0.22:61810/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/fetchFileTemp2881710203862439073.tmp
17/09/21 23:02:31 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/livy-core_2.11-0.3.0.jar to class loader
17/09/21 23:02:31 INFO Executor: Fetching spark://192.168.0.22:61810/jars/livy-rsc-0.3.0.jar with timestamp 1506060091671
17/09/21 23:02:31 INFO Utils: Fetching spark://192.168.0.22:61810/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/fetchFileTemp8955846712101889598.tmp
17/09/21 23:02:31 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/livy-rsc-0.3.0.jar to class loader
17/09/21 23:02:31 INFO Executor: Fetching spark://192.168.0.22:61810/jars/netty-all-4.0.29.Final.jar with timestamp 1506060091671
17/09/21 23:02:31 INFO Utils: Fetching spark://192.168.0.22:61810/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/fetchFileTemp755484005400538250.tmp
17/09/21 23:02:31 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4/userFiles-17afa07a-64d0-4191-ba2f-dd3cfb766def/netty-all-4.0.29.Final.jar to class loader
17/09/21 23:02:31 INFO CodeGenerator: Code generated in 16.31275 ms
17/09/21 23:02:31 INFO CodeGenerator: Code generated in 13.254936 ms
17/09/21 23:02:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/09/21 23:02:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 275 ms on localhost (executor driver) (1/1)
17/09/21 23:02:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 23:02:32 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.571 s
17/09/21 23:02:32 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.726471 s
17/09/21 23:02:39 INFO SparkSqlParser: Parsing command: df
17/09/21 23:02:40 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 23:02:40 INFO SparkSqlParser: Parsing command: `df`
17/09/21 23:02:40 INFO CodeGenerator: Code generated in 23.03931 ms
17/09/21 23:02:40 INFO CodeGenerator: Code generated in 19.86168 ms
17/09/21 23:02:40 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 23:02:40 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:02:40 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 23:02:40 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:02:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 23:02:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 23:02:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:02:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:02:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:02:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:61811 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:02:40 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 23:02:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:02:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 23:02:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 23:02:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 23:02:40 INFO CodeGenerator: Code generated in 13.559241 ms
17/09/21 23:02:40 INFO CodeGenerator: Code generated in 46.389328 ms
17/09/21 23:02:40 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 23:02:40 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:61811 (size: 464.0 B, free: 366.3 MB)
17/09/21 23:02:40 INFO CodeGenerator: Code generated in 6.860394 ms
17/09/21 23:02:40 INFO CodeGenerator: Code generated in 19.200258 ms
17/09/21 23:02:40 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2750 bytes result sent to driver
17/09/21 23:02:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 192 ms on localhost (executor driver) (1/1)
17/09/21 23:02:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 23:02:40 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.193 s
17/09/21 23:02:40 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:02:40 INFO DAGScheduler: running: Set()
17/09/21 23:02:40 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 23:02:40 INFO DAGScheduler: failed: Set()
17/09/21 23:02:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:02:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:02:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:02:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:61811 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:02:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 23:02:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:02:40 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 23:02:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 23:02:40 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 23:02:40 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:02:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/09/21 23:02:40 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/09/21 23:02:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1)
17/09/21 23:02:40 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 23:02:40 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.032 s
17/09/21 23:02:40 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.260419 s
17/09/21 23:02:40 INFO CodeGenerator: Code generated in 7.344434 ms
17/09/21 23:02:42 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:61811 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 23:02:42 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 23:02:42 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 23:02:42 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:61811 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:02:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 23:02:43 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:02:43 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 23:02:43 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 23:02:43 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 23:02:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 23:02:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 23:02:43 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 23:02:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:02:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:02:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:61811 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:02:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 23:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 23:02:43 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 23:02:43 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 23:02:43 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 23:02:43 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:02:43 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 23:02:43 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 12 ms on localhost (executor driver) (1/1)
17/09/21 23:02:43 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 23:02:43 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.012 s
17/09/21 23:02:43 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:02:43 INFO DAGScheduler: running: Set()
17/09/21 23:02:43 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 23:02:43 INFO DAGScheduler: failed: Set()
17/09/21 23:02:43 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 23:02:43 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:02:43 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:02:43 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:61811 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:02:43 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 23:02:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 23:02:43 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 23:02:43 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 23:02:43 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 23:02:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:02:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/21 23:02:43 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 23:02:43 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
17/09/21 23:02:43 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 23:02:43 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 23:02:43 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.029674 s
17/09/21 23:02:44 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 23:02:44 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:61811 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:02:44 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:61811 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:02:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 23:02:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 23:02:47 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:02:47 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 23:02:47 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 23:02:47 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:02:47 INFO DAGScheduler: Missing parents: List()
17/09/21 23:02:47 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 23:02:47 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 23:02:47 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 23:02:47 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:61811 (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:02:47 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 23:02:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 23:02:47 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 23:02:47 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 23:02:47 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 23:02:47 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:02:47 INFO CodeGenerator: Code generated in 20.761876 ms
17/09/21 23:02:47 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1521 bytes result sent to driver
17/09/21 23:02:47 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (executor driver) (1/1)
17/09/21 23:02:47 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 23:02:47 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.033 s
17/09/21 23:02:47 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.038000 s
17/09/21 23:02:47 INFO CodeGenerator: Code generated in 8.352816 ms
17/09/21 23:02:48 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 23:02:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:02:48 INFO MemoryStore: MemoryStore cleared
17/09/21 23:02:48 INFO BlockManager: BlockManager stopped
17/09/21 23:02:48 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:02:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:02:48 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:02:48 INFO SparkContext: SparkContext already stopped.
17/09/21 23:02:49 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:02:49 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8836a120-947d-4062-b35a-c73fbe7fbee4
17/09/21 23:11:00 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:11:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:11:00 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:11:00 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:11:00 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:11:00 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:11:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:11:00 INFO Utils: Successfully started service 'sparkDriver' on port 62495.
17/09/21 23:11:00 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:11:01 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:11:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:11:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:11:01 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-ffc0c3a0-b1ff-4d20-bb60-6b9d69e81355
17/09/21 23:11:01 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:11:01 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:11:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 23:11:01 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 23:11:01 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 23:11:01 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:62495/jars/sparklyr-2.1-2.11.jar with timestamp 1506060661290
17/09/21 23:11:01 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:11:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62496.
17/09/21 23:11:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:62496
17/09/21 23:11:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:11:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 62496, None)
17/09/21 23:11:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:62496 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 62496, None)
17/09/21 23:11:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 62496, None)
17/09/21 23:11:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 62496, None)
17/09/21 23:11:01 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 23:11:01 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 23:11:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:11:01 INFO MemoryStore: MemoryStore cleared
17/09/21 23:11:01 INFO BlockManager: BlockManager stopped
17/09/21 23:11:01 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:11:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:11:01 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:11:01 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:11:01 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8208b06b-79dd-437a-a37e-e8d8b627369d
17/09/21 23:11:58 INFO RSCDriver: Connecting to: 192.168.0.22:62625
17/09/21 23:11:58 INFO RSCDriver: Starting RPC server...
17/09/21 23:12:03 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 23:12:03 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 23:12:03 INFO RSCDriver: Received job request c44518bf-0669-4448-a8bf-b4afedd75149
17/09/21 23:12:03 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 23:12:05 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:12:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:12:11 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:12:11 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:12:11 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:12:11 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:12:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:12:11 INFO Utils: Successfully started service 'sparkDriver' on port 62629.
17/09/21 23:12:11 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:12:11 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:12:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:12:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:12:11 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-7c99dd00-afc4-4c4e-9366-6a4ec0cfa1e9
17/09/21 23:12:11 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:12:11 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:12:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 23:12:11 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 23:12:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:62629/jars/livy-api-0.3.0.jar with timestamp 1506060731613
17/09/21 23:12:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:62629/jars/livy-rsc-0.3.0.jar with timestamp 1506060731614
17/09/21 23:12:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:62629/jars/netty-all-4.0.29.Final.jar with timestamp 1506060731614
17/09/21 23:12:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:62629/jars/commons-codec-1.9.jar with timestamp 1506060731615
17/09/21 23:12:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:62629/jars/livy-core_2.11-0.3.0.jar with timestamp 1506060731615
17/09/21 23:12:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:62629/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506060731615
17/09/21 23:12:11 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:12:11 INFO Executor: Using REPL class URI: spark://192.168.0.22:62629/classes
17/09/21 23:12:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62630.
17/09/21 23:12:11 INFO NettyBlockTransferService: Server created on 192.168.0.22:62630
17/09/21 23:12:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:12:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 62630, None)
17/09/21 23:12:11 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:62630 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 62630, None)
17/09/21 23:12:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 62630, None)
17/09/21 23:12:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 62630, None)
17/09/21 23:12:11 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 23:12:12 INFO SparkInterpreter: Created Spark session.
17/09/21 23:12:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 23:12:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 23:13:03 INFO CodeGenerator: Code generated in 209.495373 ms
17/09/21 23:13:03 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 23:13:03 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 23:13:03 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 23:13:03 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:13:03 INFO DAGScheduler: Missing parents: List()
17/09/21 23:13:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 23:13:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 23:13:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 23:13:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:62630 (size: 4.6 KB, free: 366.3 MB)
17/09/21 23:13:03 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 23:13:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 23:13:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 23:13:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 23:13:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 23:13:03 INFO Executor: Fetching spark://192.168.0.22:62629/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506060731615
17/09/21 23:13:03 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:62629 after 8 ms (0 ms spent in bootstraps)
17/09/21 23:13:03 INFO Utils: Fetching spark://192.168.0.22:62629/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/fetchFileTemp615107087373717319.tmp
17/09/21 23:13:03 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 23:13:03 INFO Executor: Fetching spark://192.168.0.22:62629/jars/livy-core_2.11-0.3.0.jar with timestamp 1506060731615
17/09/21 23:13:03 INFO Utils: Fetching spark://192.168.0.22:62629/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/fetchFileTemp5984197011960290236.tmp
17/09/21 23:13:03 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/livy-core_2.11-0.3.0.jar to class loader
17/09/21 23:13:03 INFO Executor: Fetching spark://192.168.0.22:62629/jars/livy-rsc-0.3.0.jar with timestamp 1506060731614
17/09/21 23:13:03 INFO Utils: Fetching spark://192.168.0.22:62629/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/fetchFileTemp2283494490039176249.tmp
17/09/21 23:13:03 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/livy-rsc-0.3.0.jar to class loader
17/09/21 23:13:03 INFO Executor: Fetching spark://192.168.0.22:62629/jars/netty-all-4.0.29.Final.jar with timestamp 1506060731614
17/09/21 23:13:03 INFO Utils: Fetching spark://192.168.0.22:62629/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/fetchFileTemp4203709005382068312.tmp
17/09/21 23:13:03 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/netty-all-4.0.29.Final.jar to class loader
17/09/21 23:13:03 INFO Executor: Fetching spark://192.168.0.22:62629/jars/commons-codec-1.9.jar with timestamp 1506060731615
17/09/21 23:13:03 INFO Utils: Fetching spark://192.168.0.22:62629/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/fetchFileTemp551740939484274487.tmp
17/09/21 23:13:03 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/commons-codec-1.9.jar to class loader
17/09/21 23:13:03 INFO Executor: Fetching spark://192.168.0.22:62629/jars/livy-api-0.3.0.jar with timestamp 1506060731613
17/09/21 23:13:03 INFO Utils: Fetching spark://192.168.0.22:62629/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/fetchFileTemp8055543390461313021.tmp
17/09/21 23:13:03 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5/userFiles-89bab97c-c429-4612-9cfe-6c7bb4a2119d/livy-api-0.3.0.jar to class loader
17/09/21 23:13:03 INFO CodeGenerator: Code generated in 17.720549 ms
17/09/21 23:13:03 INFO CodeGenerator: Code generated in 14.736186 ms
17/09/21 23:13:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/09/21 23:13:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 286 ms on localhost (executor driver) (1/1)
17/09/21 23:13:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 23:13:03 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.300 s
17/09/21 23:13:03 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.747206 s
17/09/21 23:13:10 INFO SparkSqlParser: Parsing command: df
17/09/21 23:13:11 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 23:13:11 INFO SparkSqlParser: Parsing command: `df`
17/09/21 23:13:11 INFO CodeGenerator: Code generated in 14.275791 ms
17/09/21 23:13:11 INFO CodeGenerator: Code generated in 10.523953 ms
17/09/21 23:13:12 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 23:13:12 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:13:12 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 23:13:12 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:13:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 23:13:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 23:13:12 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:13:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:13:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:13:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:62630 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:13:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 23:13:12 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:13:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 23:13:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 23:13:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 23:13:12 INFO CodeGenerator: Code generated in 14.769372 ms
17/09/21 23:13:12 INFO CodeGenerator: Code generated in 43.541421 ms
17/09/21 23:13:12 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 23:13:12 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:62630 (size: 464.0 B, free: 366.3 MB)
17/09/21 23:13:12 INFO CodeGenerator: Code generated in 8.329537 ms
17/09/21 23:13:12 INFO CodeGenerator: Code generated in 19.937199 ms
17/09/21 23:13:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2750 bytes result sent to driver
17/09/21 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 186 ms on localhost (executor driver) (1/1)
17/09/21 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 23:13:12 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.188 s
17/09/21 23:13:12 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:13:12 INFO DAGScheduler: running: Set()
17/09/21 23:13:12 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 23:13:12 INFO DAGScheduler: failed: Set()
17/09/21 23:13:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:13:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:13:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:13:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:62630 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:13:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 23:13:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:13:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 23:13:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 23:13:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 23:13:12 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:13:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/09/21 23:13:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/09/21 23:13:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 28 ms on localhost (executor driver) (1/1)
17/09/21 23:13:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 23:13:12 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.029 s
17/09/21 23:13:12 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.251795 s
17/09/21 23:13:12 INFO CodeGenerator: Code generated in 7.10999 ms
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 23:13:13 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:62630 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 23:13:13 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 23:13:13 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 23:13:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:62630 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:13:14 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 23:13:15 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:13:15 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 23:13:15 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 23:13:15 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 23:13:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 23:13:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 23:13:15 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 23:13:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:13:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:13:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:62630 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:13:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 23:13:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 23:13:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 23:13:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 23:13:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 23:13:15 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:13:15 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 23:13:15 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 13 ms on localhost (executor driver) (1/1)
17/09/21 23:13:15 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 23:13:15 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.014 s
17/09/21 23:13:15 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:13:15 INFO DAGScheduler: running: Set()
17/09/21 23:13:15 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 23:13:15 INFO DAGScheduler: failed: Set()
17/09/21 23:13:15 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 23:13:15 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:13:15 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:13:15 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:62630 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:13:15 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 23:13:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 23:13:15 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 23:13:15 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 23:13:15 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 23:13:15 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:13:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/21 23:13:15 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 23:13:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
17/09/21 23:13:15 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 23:13:15 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 23:13:15 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.032069 s
17/09/21 23:13:16 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:62630 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:13:16 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 23:13:16 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:62630 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:13:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 23:13:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 23:13:19 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:13:19 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 23:13:19 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 23:13:19 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:13:19 INFO DAGScheduler: Missing parents: List()
17/09/21 23:13:19 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 23:13:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 23:13:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 23:13:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:62630 (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:13:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 23:13:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 23:13:19 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 23:13:19 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 23:13:19 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 23:13:19 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:13:19 INFO CodeGenerator: Code generated in 19.848636 ms
17/09/21 23:13:19 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1521 bytes result sent to driver
17/09/21 23:13:19 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (executor driver) (1/1)
17/09/21 23:13:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 23:13:19 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.033 s
17/09/21 23:13:19 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.038515 s
17/09/21 23:13:19 INFO CodeGenerator: Code generated in 8.504064 ms
17/09/21 23:13:19 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.22:62630 in memory (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:13:20 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 23:13:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:13:20 INFO MemoryStore: MemoryStore cleared
17/09/21 23:13:20 INFO BlockManager: BlockManager stopped
17/09/21 23:13:20 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:13:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:13:20 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:13:20 INFO SparkContext: SparkContext already stopped.
17/09/21 23:13:20 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:13:20 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-d24c2ed4-6cfa-40f4-b9c9-661258d45bf5
17/09/21 23:22:44 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:22:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:22:45 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:22:45 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:22:45 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:22:45 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:22:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:22:45 INFO Utils: Successfully started service 'sparkDriver' on port 63297.
17/09/21 23:22:45 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:22:45 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:22:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:22:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:22:45 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-6264e1ac-ce35-4739-8078-8869971bdef1
17/09/21 23:22:45 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:22:45 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:22:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 23:22:45 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 23:22:45 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 23:22:45 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:63297/jars/sparklyr-2.1-2.11.jar with timestamp 1506061365691
17/09/21 23:22:45 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:22:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63298.
17/09/21 23:22:45 INFO NettyBlockTransferService: Server created on 127.0.0.1:63298
17/09/21 23:22:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:22:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 63298, None)
17/09/21 23:22:45 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:63298 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 63298, None)
17/09/21 23:22:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 63298, None)
17/09/21 23:22:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 63298, None)
17/09/21 23:22:45 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 23:22:45 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 23:22:45 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:22:45 INFO MemoryStore: MemoryStore cleared
17/09/21 23:22:45 INFO BlockManager: BlockManager stopped
17/09/21 23:22:45 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:22:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:22:45 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:22:45 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:22:45 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-5d8d0756-cb32-406d-96ac-2aa2bc69c0c5
17/09/21 23:23:42 INFO RSCDriver: Connecting to: 192.168.0.22:63427
17/09/21 23:23:42 INFO RSCDriver: Starting RPC server...
17/09/21 23:23:48 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 23:23:48 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 23:23:48 INFO RSCDriver: Received job request 4a6aa86b-301d-43b0-ad37-02873b45ec21
17/09/21 23:23:48 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 23:23:50 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:23:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:23:56 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:23:56 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:23:56 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:23:56 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:23:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:23:56 INFO Utils: Successfully started service 'sparkDriver' on port 63432.
17/09/21 23:23:56 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:23:56 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:23:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:23:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:23:56 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-3692f013-69bc-4107-995a-e7e79eb00713
17/09/21 23:23:56 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:23:56 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:23:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 23:23:56 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 23:23:56 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:63432/jars/livy-api-0.3.0.jar with timestamp 1506061436408
17/09/21 23:23:56 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:63432/jars/livy-rsc-0.3.0.jar with timestamp 1506061436409
17/09/21 23:23:56 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:63432/jars/netty-all-4.0.29.Final.jar with timestamp 1506061436409
17/09/21 23:23:56 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:63432/jars/commons-codec-1.9.jar with timestamp 1506061436409
17/09/21 23:23:56 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:63432/jars/livy-core_2.11-0.3.0.jar with timestamp 1506061436409
17/09/21 23:23:56 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:63432/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506061436409
17/09/21 23:23:56 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:23:56 INFO Executor: Using REPL class URI: spark://192.168.0.22:63432/classes
17/09/21 23:23:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 63433.
17/09/21 23:23:56 INFO NettyBlockTransferService: Server created on 192.168.0.22:63433
17/09/21 23:23:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:23:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 63433, None)
17/09/21 23:23:56 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:63433 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 63433, None)
17/09/21 23:23:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 63433, None)
17/09/21 23:23:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 63433, None)
17/09/21 23:23:56 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 23:23:56 INFO SparkInterpreter: Created Spark session.
17/09/21 23:24:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 23:24:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 23:24:56 INFO CodeGenerator: Code generated in 176.997021 ms
17/09/21 23:24:56 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 23:24:56 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 23:24:56 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 23:24:56 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:24:56 INFO DAGScheduler: Missing parents: List()
17/09/21 23:24:56 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 23:24:56 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 23:24:56 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 23:24:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:63433 (size: 4.6 KB, free: 366.3 MB)
17/09/21 23:24:56 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 23:24:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 23:24:56 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 23:24:56 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 23:24:56 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 23:24:56 INFO Executor: Fetching spark://192.168.0.22:63432/jars/commons-codec-1.9.jar with timestamp 1506061436409
17/09/21 23:24:56 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:63432 after 7 ms (0 ms spent in bootstraps)
17/09/21 23:24:56 INFO Utils: Fetching spark://192.168.0.22:63432/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/fetchFileTemp7324253774838175649.tmp
17/09/21 23:24:56 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/commons-codec-1.9.jar to class loader
17/09/21 23:24:56 INFO Executor: Fetching spark://192.168.0.22:63432/jars/netty-all-4.0.29.Final.jar with timestamp 1506061436409
17/09/21 23:24:56 INFO Utils: Fetching spark://192.168.0.22:63432/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/fetchFileTemp2722878512332607834.tmp
17/09/21 23:24:56 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/netty-all-4.0.29.Final.jar to class loader
17/09/21 23:24:56 INFO Executor: Fetching spark://192.168.0.22:63432/jars/livy-api-0.3.0.jar with timestamp 1506061436408
17/09/21 23:24:56 INFO Utils: Fetching spark://192.168.0.22:63432/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/fetchFileTemp7530717911224754406.tmp
17/09/21 23:24:56 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/livy-api-0.3.0.jar to class loader
17/09/21 23:24:56 INFO Executor: Fetching spark://192.168.0.22:63432/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506061436409
17/09/21 23:24:56 INFO Utils: Fetching spark://192.168.0.22:63432/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/fetchFileTemp4279099391430411528.tmp
17/09/21 23:24:56 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 23:24:56 INFO Executor: Fetching spark://192.168.0.22:63432/jars/livy-core_2.11-0.3.0.jar with timestamp 1506061436409
17/09/21 23:24:56 INFO Utils: Fetching spark://192.168.0.22:63432/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/fetchFileTemp5476875206169696922.tmp
17/09/21 23:24:56 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/livy-core_2.11-0.3.0.jar to class loader
17/09/21 23:24:56 INFO Executor: Fetching spark://192.168.0.22:63432/jars/livy-rsc-0.3.0.jar with timestamp 1506061436409
17/09/21 23:24:56 INFO Utils: Fetching spark://192.168.0.22:63432/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/fetchFileTemp4491118974875096516.tmp
17/09/21 23:24:56 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f/userFiles-0fb92641-f8db-4be2-8992-33c4192fe668/livy-rsc-0.3.0.jar to class loader
17/09/21 23:24:56 INFO CodeGenerator: Code generated in 16.37979 ms
17/09/21 23:24:56 INFO CodeGenerator: Code generated in 14.116009 ms
17/09/21 23:24:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/09/21 23:24:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 582 ms on localhost (executor driver) (1/1)
17/09/21 23:24:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 23:24:56 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.596 s
17/09/21 23:24:56 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.773399 s
17/09/21 23:25:03 INFO SparkSqlParser: Parsing command: df
17/09/21 23:25:05 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 23:25:05 INFO SparkSqlParser: Parsing command: `df`
17/09/21 23:25:05 INFO CodeGenerator: Code generated in 15.317129 ms
17/09/21 23:25:05 INFO CodeGenerator: Code generated in 10.742561 ms
17/09/21 23:25:05 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 23:25:05 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:25:05 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 23:25:05 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:25:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 23:25:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 23:25:05 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:25:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:25:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:25:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:63433 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:25:05 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 23:25:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:25:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 23:25:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 23:25:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 23:25:05 INFO CodeGenerator: Code generated in 11.359178 ms
17/09/21 23:25:05 INFO CodeGenerator: Code generated in 45.668926 ms
17/09/21 23:25:05 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 23:25:05 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:63433 (size: 464.0 B, free: 366.3 MB)
17/09/21 23:25:05 INFO CodeGenerator: Code generated in 6.852604 ms
17/09/21 23:25:05 INFO CodeGenerator: Code generated in 20.101287 ms
17/09/21 23:25:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2750 bytes result sent to driver
17/09/21 23:25:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 183 ms on localhost (executor driver) (1/1)
17/09/21 23:25:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 23:25:05 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.185 s
17/09/21 23:25:05 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:25:05 INFO DAGScheduler: running: Set()
17/09/21 23:25:05 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 23:25:05 INFO DAGScheduler: failed: Set()
17/09/21 23:25:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:25:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:25:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:25:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:63433 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:25:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 23:25:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:25:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 23:25:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 23:25:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 23:25:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:25:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/09/21 23:25:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/09/21 23:25:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
17/09/21 23:25:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 23:25:05 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.030 s
17/09/21 23:25:05 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.250855 s
17/09/21 23:25:05 INFO CodeGenerator: Code generated in 8.211385 ms
17/09/21 23:25:07 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:63433 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 23:25:07 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 23:25:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:63433 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 23:25:07 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 23:25:07 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 23:25:08 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:25:08 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 23:25:08 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 23:25:08 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 23:25:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 23:25:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 23:25:08 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 23:25:08 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:25:08 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:25:08 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:63433 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:25:08 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 23:25:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 23:25:08 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 23:25:08 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 23:25:08 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 23:25:08 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:25:08 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 23:25:08 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 13 ms on localhost (executor driver) (1/1)
17/09/21 23:25:08 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 23:25:08 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.013 s
17/09/21 23:25:08 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:25:08 INFO DAGScheduler: running: Set()
17/09/21 23:25:08 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 23:25:08 INFO DAGScheduler: failed: Set()
17/09/21 23:25:08 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 23:25:08 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:25:08 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:25:08 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:63433 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:25:08 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 23:25:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 23:25:08 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 23:25:08 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 23:25:08 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 23:25:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:25:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/09/21 23:25:08 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 23:25:08 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 5 ms on localhost (executor driver) (1/1)
17/09/21 23:25:08 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 23:25:08 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 23:25:08 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.030193 s
17/09/21 23:25:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 23:25:10 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:63433 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:25:10 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 23:25:10 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:63433 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:25:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 23:25:12 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:25:12 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 23:25:12 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 23:25:12 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:25:12 INFO DAGScheduler: Missing parents: List()
17/09/21 23:25:12 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 23:25:12 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 23:25:12 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 23:25:12 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:63433 (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:25:12 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 23:25:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 23:25:12 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 23:25:12 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 23:25:12 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 23:25:12 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:25:12 INFO CodeGenerator: Code generated in 21.37442 ms
17/09/21 23:25:12 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1521 bytes result sent to driver
17/09/21 23:25:12 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 36 ms on localhost (executor driver) (1/1)
17/09/21 23:25:12 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 23:25:12 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.036 s
17/09/21 23:25:12 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.041096 s
17/09/21 23:25:12 INFO CodeGenerator: Code generated in 7.384886 ms
17/09/21 23:25:13 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.22:63433 in memory (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:25:13 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 23:25:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:25:13 INFO MemoryStore: MemoryStore cleared
17/09/21 23:25:13 INFO BlockManager: BlockManager stopped
17/09/21 23:25:13 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:25:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:25:13 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:25:13 INFO SparkContext: SparkContext already stopped.
17/09/21 23:25:13 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:25:13 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-c247a472-6a35-4888-afc6-b0500ac4e45f
17/09/21 23:31:50 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:31:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:31:51 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:31:51 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:31:51 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:31:51 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:31:51 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:31:51 INFO Utils: Successfully started service 'sparkDriver' on port 64039.
17/09/21 23:31:51 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:31:51 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:31:51 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:31:51 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:31:51 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-8aa777b0-da95-45ef-96e2-bc5b8a432087
17/09/21 23:31:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:31:51 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:31:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 23:31:51 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 23:31:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 23:31:51 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64039/jars/sparklyr-2.1-2.11.jar with timestamp 1506061911460
17/09/21 23:31:51 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:31:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64040.
17/09/21 23:31:51 INFO NettyBlockTransferService: Server created on 127.0.0.1:64040
17/09/21 23:31:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:31:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64040, None)
17/09/21 23:31:51 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64040 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64040, None)
17/09/21 23:31:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64040, None)
17/09/21 23:31:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64040, None)
17/09/21 23:31:51 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 23:31:51 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 23:31:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:31:51 INFO MemoryStore: MemoryStore cleared
17/09/21 23:31:51 INFO BlockManager: BlockManager stopped
17/09/21 23:31:51 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:31:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:31:51 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:31:51 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:31:51 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-32274bce-2df3-48b4-bf02-6fbf59ab892a
17/09/21 23:32:48 INFO RSCDriver: Connecting to: 192.168.0.22:64169
17/09/21 23:32:48 INFO RSCDriver: Starting RPC server...
17/09/21 23:32:53 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 23:32:53 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 23:32:54 INFO RSCDriver: Received job request bb02c1ab-020b-4c32-b4c1-eee967955b04
17/09/21 23:32:54 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 23:32:56 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:32:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:33:01 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:33:01 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:33:01 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:33:01 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:33:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:33:01 INFO Utils: Successfully started service 'sparkDriver' on port 64174.
17/09/21 23:33:01 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:33:01 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:33:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:33:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:33:01 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-ff6f7ef4-e246-417f-aac0-83b4aa166abe
17/09/21 23:33:01 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:33:01 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:33:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 23:33:02 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 23:33:02 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:64174/jars/livy-api-0.3.0.jar with timestamp 1506061982205
17/09/21 23:33:02 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:64174/jars/livy-rsc-0.3.0.jar with timestamp 1506061982206
17/09/21 23:33:02 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:64174/jars/netty-all-4.0.29.Final.jar with timestamp 1506061982206
17/09/21 23:33:02 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:64174/jars/commons-codec-1.9.jar with timestamp 1506061982206
17/09/21 23:33:02 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:64174/jars/livy-core_2.11-0.3.0.jar with timestamp 1506061982206
17/09/21 23:33:02 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:64174/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506061982206
17/09/21 23:33:02 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:33:02 INFO Executor: Using REPL class URI: spark://192.168.0.22:64174/classes
17/09/21 23:33:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64175.
17/09/21 23:33:02 INFO NettyBlockTransferService: Server created on 192.168.0.22:64175
17/09/21 23:33:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:33:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 64175, None)
17/09/21 23:33:02 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:64175 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 64175, None)
17/09/21 23:33:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 64175, None)
17/09/21 23:33:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 64175, None)
17/09/21 23:33:02 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 23:33:02 INFO SparkInterpreter: Created Spark session.
17/09/21 23:33:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 23:33:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 23:34:01 INFO CodeGenerator: Code generated in 175.628781 ms
17/09/21 23:34:01 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 23:34:01 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 23:34:01 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 23:34:01 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:34:01 INFO DAGScheduler: Missing parents: List()
17/09/21 23:34:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 23:34:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 23:34:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 23:34:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:64175 (size: 4.6 KB, free: 366.3 MB)
17/09/21 23:34:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 23:34:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 23:34:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 23:34:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 23:34:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 23:34:02 INFO Executor: Fetching spark://192.168.0.22:64174/jars/commons-codec-1.9.jar with timestamp 1506061982206
17/09/21 23:34:02 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:64174 after 7 ms (0 ms spent in bootstraps)
17/09/21 23:34:02 INFO Utils: Fetching spark://192.168.0.22:64174/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/fetchFileTemp7431476239598302243.tmp
17/09/21 23:34:02 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/commons-codec-1.9.jar to class loader
17/09/21 23:34:02 INFO Executor: Fetching spark://192.168.0.22:64174/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506061982206
17/09/21 23:34:02 INFO Utils: Fetching spark://192.168.0.22:64174/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/fetchFileTemp5188882020609417325.tmp
17/09/21 23:34:02 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 23:34:02 INFO Executor: Fetching spark://192.168.0.22:64174/jars/livy-api-0.3.0.jar with timestamp 1506061982205
17/09/21 23:34:02 INFO Utils: Fetching spark://192.168.0.22:64174/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/fetchFileTemp2706429480520917934.tmp
17/09/21 23:34:02 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/livy-api-0.3.0.jar to class loader
17/09/21 23:34:02 INFO Executor: Fetching spark://192.168.0.22:64174/jars/netty-all-4.0.29.Final.jar with timestamp 1506061982206
17/09/21 23:34:02 INFO Utils: Fetching spark://192.168.0.22:64174/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/fetchFileTemp5043641245278886610.tmp
17/09/21 23:34:02 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/netty-all-4.0.29.Final.jar to class loader
17/09/21 23:34:02 INFO Executor: Fetching spark://192.168.0.22:64174/jars/livy-core_2.11-0.3.0.jar with timestamp 1506061982206
17/09/21 23:34:02 INFO Utils: Fetching spark://192.168.0.22:64174/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/fetchFileTemp8656328447911473525.tmp
17/09/21 23:34:02 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/livy-core_2.11-0.3.0.jar to class loader
17/09/21 23:34:02 INFO Executor: Fetching spark://192.168.0.22:64174/jars/livy-rsc-0.3.0.jar with timestamp 1506061982206
17/09/21 23:34:02 INFO Utils: Fetching spark://192.168.0.22:64174/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/fetchFileTemp3809914785658223346.tmp
17/09/21 23:34:02 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253/userFiles-03e001a2-5922-42cf-a48c-f70c6d066a32/livy-rsc-0.3.0.jar to class loader
17/09/21 23:34:02 INFO CodeGenerator: Code generated in 16.693787 ms
17/09/21 23:34:02 INFO CodeGenerator: Code generated in 14.042941 ms
17/09/21 23:34:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/09/21 23:34:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 276 ms on localhost (executor driver) (1/1)
17/09/21 23:34:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 23:34:02 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.289 s
17/09/21 23:34:02 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.769912 s
17/09/21 23:34:09 INFO SparkSqlParser: Parsing command: df
17/09/21 23:34:10 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 23:34:10 INFO SparkSqlParser: Parsing command: `df`
17/09/21 23:34:10 INFO CodeGenerator: Code generated in 14.927037 ms
17/09/21 23:34:10 INFO CodeGenerator: Code generated in 11.397243 ms
17/09/21 23:34:11 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 23:34:11 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:34:11 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 23:34:11 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:34:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 23:34:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 23:34:11 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:34:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:34:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:34:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:64175 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:34:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 23:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:34:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 23:34:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 23:34:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 23:34:11 INFO CodeGenerator: Code generated in 13.150805 ms
17/09/21 23:34:11 INFO CodeGenerator: Code generated in 44.788709 ms
17/09/21 23:34:11 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 23:34:11 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:64175 (size: 464.0 B, free: 366.3 MB)
17/09/21 23:34:11 INFO CodeGenerator: Code generated in 9.112945 ms
17/09/21 23:34:11 INFO CodeGenerator: Code generated in 20.135343 ms
17/09/21 23:34:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2750 bytes result sent to driver
17/09/21 23:34:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 187 ms on localhost (executor driver) (1/1)
17/09/21 23:34:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 23:34:11 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.188 s
17/09/21 23:34:11 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:34:11 INFO DAGScheduler: running: Set()
17/09/21 23:34:11 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 23:34:11 INFO DAGScheduler: failed: Set()
17/09/21 23:34:11 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:34:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:34:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:34:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:64175 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:34:11 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 23:34:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:34:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 23:34:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 23:34:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 23:34:11 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:34:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/09/21 23:34:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/09/21 23:34:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
17/09/21 23:34:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 23:34:11 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s
17/09/21 23:34:11 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.254526 s
17/09/21 23:34:11 INFO CodeGenerator: Code generated in 7.129731 ms
17/09/21 23:34:12 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:64175 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 23:34:12 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 23:34:12 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 23:34:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:64175 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:34:12 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 23:34:14 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:34:14 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 23:34:14 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 23:34:14 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 23:34:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 23:34:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 23:34:14 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 23:34:14 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:34:14 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:34:14 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:64175 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:34:14 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 23:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 23:34:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 23:34:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 23:34:14 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 23:34:14 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:34:14 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 23:34:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 12 ms on localhost (executor driver) (1/1)
17/09/21 23:34:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 23:34:14 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.012 s
17/09/21 23:34:14 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:34:14 INFO DAGScheduler: running: Set()
17/09/21 23:34:14 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 23:34:14 INFO DAGScheduler: failed: Set()
17/09/21 23:34:14 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 23:34:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:34:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:34:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:64175 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:34:14 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 23:34:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 23:34:14 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 23:34:14 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 23:34:14 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 23:34:14 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:34:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/21 23:34:14 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 23:34:14 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
17/09/21 23:34:14 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 23:34:14 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 23:34:14 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.030946 s
17/09/21 23:34:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 23:34:15 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 23:34:15 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:64175 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:34:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:64175 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:34:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 23:34:18 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:34:18 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 23:34:18 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 23:34:18 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:34:18 INFO DAGScheduler: Missing parents: List()
17/09/21 23:34:18 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 23:34:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 23:34:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 23:34:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:64175 (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:34:18 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 23:34:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 23:34:18 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 23:34:18 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 23:34:18 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 23:34:18 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:34:18 INFO CodeGenerator: Code generated in 19.502105 ms
17/09/21 23:34:18 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1521 bytes result sent to driver
17/09/21 23:34:18 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 33 ms on localhost (executor driver) (1/1)
17/09/21 23:34:18 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 23:34:18 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.033 s
17/09/21 23:34:18 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.038694 s
17/09/21 23:34:18 INFO CodeGenerator: Code generated in 7.7031 ms
17/09/21 23:34:18 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.22:64175 in memory (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:34:19 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 23:34:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:34:19 INFO MemoryStore: MemoryStore cleared
17/09/21 23:34:19 INFO BlockManager: BlockManager stopped
17/09/21 23:34:19 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:34:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:34:19 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:34:19 INFO SparkContext: SparkContext already stopped.
17/09/21 23:34:19 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:34:19 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-477b6349-60be-49b7-951b-1e999e783253
17/09/21 23:41:00 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:41:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:41:00 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:41:00 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:41:00 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:41:00 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:41:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:41:00 INFO Utils: Successfully started service 'sparkDriver' on port 64919.
17/09/21 23:41:00 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:41:00 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:41:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:41:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:41:00 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-81367874-20dc-494a-b2af-18e2106b097d
17/09/21 23:41:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:41:00 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:41:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 23:41:01 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 23:41:01 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 23:41:01 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64919/jars/sparklyr-2.1-2.11.jar with timestamp 1506062461125
17/09/21 23:41:01 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:41:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64920.
17/09/21 23:41:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:64920
17/09/21 23:41:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:41:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64920, None)
17/09/21 23:41:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64920 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64920, None)
17/09/21 23:41:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64920, None)
17/09/21 23:41:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64920, None)
17/09/21 23:41:01 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 23:41:01 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 23:41:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:41:01 INFO MemoryStore: MemoryStore cleared
17/09/21 23:41:01 INFO BlockManager: BlockManager stopped
17/09/21 23:41:01 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:41:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:41:01 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:41:01 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:41:01 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-376d5ec1-63da-4c3e-944f-057ee57f2d0c
17/09/21 23:41:57 INFO RSCDriver: Connecting to: 192.168.0.22:65051
17/09/21 23:41:57 INFO RSCDriver: Starting RPC server...
17/09/21 23:42:03 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 23:42:03 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 23:42:03 INFO RSCDriver: Received job request 7352183c-be09-412d-be1a-8ce37f3c16de
17/09/21 23:42:03 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 23:42:05 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:42:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:42:10 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:42:10 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:42:10 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:42:10 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:42:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:42:11 INFO Utils: Successfully started service 'sparkDriver' on port 65055.
17/09/21 23:42:11 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:42:11 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:42:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:42:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:42:11 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-29938dab-67be-448f-95e3-d984c7415fb2
17/09/21 23:42:11 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:42:11 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:42:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 23:42:11 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 23:42:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:65055/jars/livy-api-0.3.0.jar with timestamp 1506062531368
17/09/21 23:42:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:65055/jars/livy-rsc-0.3.0.jar with timestamp 1506062531368
17/09/21 23:42:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:65055/jars/netty-all-4.0.29.Final.jar with timestamp 1506062531369
17/09/21 23:42:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:65055/jars/commons-codec-1.9.jar with timestamp 1506062531369
17/09/21 23:42:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:65055/jars/livy-core_2.11-0.3.0.jar with timestamp 1506062531369
17/09/21 23:42:11 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:65055/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506062531369
17/09/21 23:42:11 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:42:11 INFO Executor: Using REPL class URI: spark://192.168.0.22:65055/classes
17/09/21 23:42:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65056.
17/09/21 23:42:11 INFO NettyBlockTransferService: Server created on 192.168.0.22:65056
17/09/21 23:42:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:42:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 65056, None)
17/09/21 23:42:11 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:65056 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 65056, None)
17/09/21 23:42:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 65056, None)
17/09/21 23:42:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 65056, None)
17/09/21 23:42:11 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 23:42:11 INFO SparkInterpreter: Created Spark session.
17/09/21 23:42:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 23:43:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 23:43:11 INFO CodeGenerator: Code generated in 173.301203 ms
17/09/21 23:43:11 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 23:43:11 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 23:43:11 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 23:43:11 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:43:11 INFO DAGScheduler: Missing parents: List()
17/09/21 23:43:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 23:43:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 23:43:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 23:43:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:65056 (size: 4.6 KB, free: 366.3 MB)
17/09/21 23:43:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 23:43:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 23:43:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 23:43:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 23:43:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 23:43:11 INFO Executor: Fetching spark://192.168.0.22:65055/jars/netty-all-4.0.29.Final.jar with timestamp 1506062531369
17/09/21 23:43:11 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:65055 after 8 ms (0 ms spent in bootstraps)
17/09/21 23:43:11 INFO Utils: Fetching spark://192.168.0.22:65055/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/fetchFileTemp8296663288582320252.tmp
17/09/21 23:43:11 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/netty-all-4.0.29.Final.jar to class loader
17/09/21 23:43:11 INFO Executor: Fetching spark://192.168.0.22:65055/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506062531369
17/09/21 23:43:11 INFO Utils: Fetching spark://192.168.0.22:65055/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/fetchFileTemp1929151120104353716.tmp
17/09/21 23:43:11 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 23:43:11 INFO Executor: Fetching spark://192.168.0.22:65055/jars/commons-codec-1.9.jar with timestamp 1506062531369
17/09/21 23:43:11 INFO Utils: Fetching spark://192.168.0.22:65055/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/fetchFileTemp7497623880070878067.tmp
17/09/21 23:43:11 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/commons-codec-1.9.jar to class loader
17/09/21 23:43:11 INFO Executor: Fetching spark://192.168.0.22:65055/jars/livy-rsc-0.3.0.jar with timestamp 1506062531368
17/09/21 23:43:11 INFO Utils: Fetching spark://192.168.0.22:65055/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/fetchFileTemp8090811006927796079.tmp
17/09/21 23:43:11 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/livy-rsc-0.3.0.jar to class loader
17/09/21 23:43:11 INFO Executor: Fetching spark://192.168.0.22:65055/jars/livy-core_2.11-0.3.0.jar with timestamp 1506062531369
17/09/21 23:43:11 INFO Utils: Fetching spark://192.168.0.22:65055/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/fetchFileTemp6172253954319967008.tmp
17/09/21 23:43:11 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/livy-core_2.11-0.3.0.jar to class loader
17/09/21 23:43:11 INFO Executor: Fetching spark://192.168.0.22:65055/jars/livy-api-0.3.0.jar with timestamp 1506062531368
17/09/21 23:43:11 INFO Utils: Fetching spark://192.168.0.22:65055/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/fetchFileTemp2760196608958581909.tmp
17/09/21 23:43:11 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd/userFiles-23c6976e-e093-47aa-a2bd-432cd414e3d3/livy-api-0.3.0.jar to class loader
17/09/21 23:43:11 INFO CodeGenerator: Code generated in 17.487427 ms
17/09/21 23:43:11 INFO CodeGenerator: Code generated in 14.643138 ms
17/09/21 23:43:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/09/21 23:43:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 297 ms on localhost (executor driver) (1/1)
17/09/21 23:43:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 23:43:12 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.597 s
17/09/21 23:43:12 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.761231 s
17/09/21 23:43:19 INFO SparkSqlParser: Parsing command: df
17/09/21 23:43:20 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 23:43:20 INFO SparkSqlParser: Parsing command: `df`
17/09/21 23:43:20 INFO CodeGenerator: Code generated in 15.4107 ms
17/09/21 23:43:20 INFO CodeGenerator: Code generated in 11.262708 ms
17/09/21 23:43:20 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 23:43:20 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:43:20 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 23:43:20 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:43:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 23:43:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 23:43:20 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:43:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:43:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:43:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:65056 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:43:20 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 23:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:43:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 23:43:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 23:43:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 23:43:20 INFO CodeGenerator: Code generated in 12.181534 ms
17/09/21 23:43:20 INFO CodeGenerator: Code generated in 40.694485 ms
17/09/21 23:43:20 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 23:43:20 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:65056 (size: 464.0 B, free: 366.3 MB)
17/09/21 23:43:20 INFO CodeGenerator: Code generated in 7.341138 ms
17/09/21 23:43:20 INFO CodeGenerator: Code generated in 19.697835 ms
17/09/21 23:43:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2750 bytes result sent to driver
17/09/21 23:43:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 176 ms on localhost (executor driver) (1/1)
17/09/21 23:43:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 23:43:20 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.177 s
17/09/21 23:43:20 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:43:20 INFO DAGScheduler: running: Set()
17/09/21 23:43:20 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 23:43:20 INFO DAGScheduler: failed: Set()
17/09/21 23:43:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:43:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:43:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:43:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:65056 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:43:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 23:43:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:43:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 23:43:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 23:43:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 23:43:20 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:43:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/09/21 23:43:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2129 bytes result sent to driver
17/09/21 23:43:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1)
17/09/21 23:43:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 23:43:20 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s
17/09/21 23:43:20 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.242126 s
17/09/21 23:43:20 INFO CodeGenerator: Code generated in 8.281533 ms
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 23:43:22 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 23:43:22 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 23:43:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:65056 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:43:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:65056 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:43:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 23:43:23 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:43:23 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 23:43:23 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 23:43:23 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 23:43:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 23:43:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 23:43:23 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 23:43:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:43:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:43:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:65056 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:43:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 23:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 23:43:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 23:43:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 23:43:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 23:43:23 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:43:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 23:43:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 13 ms on localhost (executor driver) (1/1)
17/09/21 23:43:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 23:43:23 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.015 s
17/09/21 23:43:23 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:43:23 INFO DAGScheduler: running: Set()
17/09/21 23:43:23 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 23:43:23 INFO DAGScheduler: failed: Set()
17/09/21 23:43:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 23:43:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:43:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:43:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:65056 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:43:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 23:43:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 23:43:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 23:43:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 23:43:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 23:43:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:43:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/21 23:43:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 23:43:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1)
17/09/21 23:43:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 23:43:23 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.007 s
17/09/21 23:43:23 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.034297 s
17/09/21 23:43:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 23:43:25 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:65056 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:43:25 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 23:43:25 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:65056 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:43:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 23:43:28 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:43:28 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 23:43:28 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 23:43:28 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:43:28 INFO DAGScheduler: Missing parents: List()
17/09/21 23:43:28 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 23:43:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 23:43:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 23:43:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:65056 (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:43:28 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 23:43:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 23:43:28 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 23:43:28 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 23:43:28 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 23:43:28 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:43:28 INFO CodeGenerator: Code generated in 22.095694 ms
17/09/21 23:43:28 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1521 bytes result sent to driver
17/09/21 23:43:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 35 ms on localhost (executor driver) (1/1)
17/09/21 23:43:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 23:43:28 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.035 s
17/09/21 23:43:28 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.040403 s
17/09/21 23:43:28 INFO CodeGenerator: Code generated in 7.89947 ms
17/09/21 23:43:28 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.22:65056 in memory (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:43:29 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 23:43:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:43:29 INFO MemoryStore: MemoryStore cleared
17/09/21 23:43:29 INFO BlockManager: BlockManager stopped
17/09/21 23:43:29 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:43:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:43:29 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:43:29 INFO SparkContext: SparkContext already stopped.
17/09/21 23:43:29 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:43:29 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-0331cab1-6996-4453-bf7f-05f826b7b8cd
17/09/21 23:50:02 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:50:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:50:02 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:50:02 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:50:02 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:50:02 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:50:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:50:02 INFO Utils: Successfully started service 'sparkDriver' on port 49248.
17/09/21 23:50:02 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:50:02 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:50:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:50:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:50:02 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-0a071b75-7112-40bb-9ea7-02a756f45d6b
17/09/21 23:50:02 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:50:02 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:50:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 23:50:03 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 23:50:03 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 23:50:03 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:49248/jars/sparklyr-2.1-2.11.jar with timestamp 1506063003172
17/09/21 23:50:03 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:50:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49249.
17/09/21 23:50:03 INFO NettyBlockTransferService: Server created on 127.0.0.1:49249
17/09/21 23:50:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:50:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49249, None)
17/09/21 23:50:03 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49249 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49249, None)
17/09/21 23:50:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49249, None)
17/09/21 23:50:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49249, None)
17/09/21 23:50:03 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 23:50:03 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 23:50:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:50:03 INFO MemoryStore: MemoryStore cleared
17/09/21 23:50:03 INFO BlockManager: BlockManager stopped
17/09/21 23:50:03 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:50:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:50:03 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:50:03 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:50:03 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-eb230060-d76a-419f-94f0-6d3255d5e036
17/09/21 23:51:00 INFO RSCDriver: Connecting to: 192.168.0.22:49381
17/09/21 23:51:00 INFO RSCDriver: Starting RPC server...
17/09/21 23:51:05 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 23:51:05 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 23:51:05 INFO RSCDriver: Received job request 25d0de9e-6780-4b8f-bf99-f62f12d0793f
17/09/21 23:51:05 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 23:51:08 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:51:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:51:13 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:51:13 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:51:13 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:51:13 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:51:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:51:13 INFO Utils: Successfully started service 'sparkDriver' on port 49385.
17/09/21 23:51:13 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:51:13 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:51:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:51:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:51:13 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-90cc8b6e-9f0e-4d7b-ace4-1eac0b7a41cc
17/09/21 23:51:13 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:51:13 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:51:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 23:51:13 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 23:51:13 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:49385/jars/livy-api-0.3.0.jar with timestamp 1506063073881
17/09/21 23:51:13 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:49385/jars/livy-rsc-0.3.0.jar with timestamp 1506063073883
17/09/21 23:51:13 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:49385/jars/netty-all-4.0.29.Final.jar with timestamp 1506063073883
17/09/21 23:51:13 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:49385/jars/commons-codec-1.9.jar with timestamp 1506063073883
17/09/21 23:51:13 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:49385/jars/livy-core_2.11-0.3.0.jar with timestamp 1506063073883
17/09/21 23:51:13 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:49385/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506063073883
17/09/21 23:51:13 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:51:13 INFO Executor: Using REPL class URI: spark://192.168.0.22:49385/classes
17/09/21 23:51:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49386.
17/09/21 23:51:13 INFO NettyBlockTransferService: Server created on 192.168.0.22:49386
17/09/21 23:51:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:51:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 49386, None)
17/09/21 23:51:13 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:49386 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 49386, None)
17/09/21 23:51:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 49386, None)
17/09/21 23:51:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 49386, None)
17/09/21 23:51:14 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 23:51:14 INFO SparkInterpreter: Created Spark session.
17/09/21 23:52:01 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/09/21 23:52:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/09/21 23:52:13 INFO CodeGenerator: Code generated in 177.915692 ms
17/09/21 23:52:13 INFO SparkContext: Starting job: collect at <console>:86
17/09/21 23:52:13 INFO DAGScheduler: Got job 0 (collect at <console>:86) with 1 output partitions
17/09/21 23:52:13 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <console>:86)
17/09/21 23:52:13 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:52:13 INFO DAGScheduler: Missing parents: List()
17/09/21 23:52:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83), which has no missing parents
17/09/21 23:52:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
17/09/21 23:52:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/09/21 23:52:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.0.22:49386 (size: 4.6 KB, free: 366.3 MB)
17/09/21 23:52:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/09/21 23:52:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at <console>:83)
17/09/21 23:52:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/09/21 23:52:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6480 bytes)
17/09/21 23:52:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/21 23:52:13 INFO Executor: Fetching spark://192.168.0.22:49385/jars/livy-api-0.3.0.jar with timestamp 1506063073881
17/09/21 23:52:13 INFO TransportClientFactory: Successfully created connection to /192.168.0.22:49385 after 8 ms (0 ms spent in bootstraps)
17/09/21 23:52:13 INFO Utils: Fetching spark://192.168.0.22:49385/jars/livy-api-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/fetchFileTemp5489951305028344745.tmp
17/09/21 23:52:13 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/livy-api-0.3.0.jar to class loader
17/09/21 23:52:13 INFO Executor: Fetching spark://192.168.0.22:49385/jars/commons-codec-1.9.jar with timestamp 1506063073883
17/09/21 23:52:13 INFO Utils: Fetching spark://192.168.0.22:49385/jars/commons-codec-1.9.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/fetchFileTemp850115713261126521.tmp
17/09/21 23:52:13 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/commons-codec-1.9.jar to class loader
17/09/21 23:52:13 INFO Executor: Fetching spark://192.168.0.22:49385/jars/livy-rsc-0.3.0.jar with timestamp 1506063073883
17/09/21 23:52:13 INFO Utils: Fetching spark://192.168.0.22:49385/jars/livy-rsc-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/fetchFileTemp3752657007157369417.tmp
17/09/21 23:52:13 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/livy-rsc-0.3.0.jar to class loader
17/09/21 23:52:13 INFO Executor: Fetching spark://192.168.0.22:49385/jars/netty-all-4.0.29.Final.jar with timestamp 1506063073883
17/09/21 23:52:13 INFO Utils: Fetching spark://192.168.0.22:49385/jars/netty-all-4.0.29.Final.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/fetchFileTemp6513475271752245352.tmp
17/09/21 23:52:13 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/netty-all-4.0.29.Final.jar to class loader
17/09/21 23:52:13 INFO Executor: Fetching spark://192.168.0.22:49385/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506063073883
17/09/21 23:52:13 INFO Utils: Fetching spark://192.168.0.22:49385/jars/livy-repl_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/fetchFileTemp3276978963066182648.tmp
17/09/21 23:52:13 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/livy-repl_2.11-0.3.0.jar to class loader
17/09/21 23:52:13 INFO Executor: Fetching spark://192.168.0.22:49385/jars/livy-core_2.11-0.3.0.jar with timestamp 1506063073883
17/09/21 23:52:13 INFO Utils: Fetching spark://192.168.0.22:49385/jars/livy-core_2.11-0.3.0.jar to /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/fetchFileTemp3172252237336239890.tmp
17/09/21 23:52:13 INFO Executor: Adding file:/private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e/userFiles-6946575b-0085-4b8e-8648-684f6a012f8e/livy-core_2.11-0.3.0.jar to class loader
17/09/21 23:52:14 INFO CodeGenerator: Code generated in 17.159805 ms
17/09/21 23:52:14 INFO CodeGenerator: Code generated in 13.506348 ms
17/09/21 23:52:14 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/09/21 23:52:14 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 283 ms on localhost (executor driver) (1/1)
17/09/21 23:52:14 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/09/21 23:52:14 INFO DAGScheduler: ResultStage 0 (collect at <console>:86) finished in 0.297 s
17/09/21 23:52:14 INFO DAGScheduler: Job 0 finished: collect at <console>:86, took 0.789950 s
17/09/21 23:52:21 INFO SparkSqlParser: Parsing command: df
17/09/21 23:52:22 INFO SparkSqlParser: Parsing command: CACHE TABLE `df`
17/09/21 23:52:22 INFO SparkSqlParser: Parsing command: `df`
17/09/21 23:52:22 INFO CodeGenerator: Code generated in 15.121701 ms
17/09/21 23:52:22 INFO CodeGenerator: Code generated in 11.390045 ms
17/09/21 23:52:22 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/09/21 23:52:22 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:52:22 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/09/21 23:52:22 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:52:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/09/21 23:52:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/09/21 23:52:22 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:52:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:52:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:52:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.0.22:49386 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:52:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/09/21 23:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:52:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/21 23:52:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6704 bytes)
17/09/21 23:52:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/09/21 23:52:22 INFO CodeGenerator: Code generated in 12.801027 ms
17/09/21 23:52:22 INFO CodeGenerator: Code generated in 42.431894 ms
17/09/21 23:52:22 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 464.0 B, free 366.3 MB)
17/09/21 23:52:22 INFO BlockManagerInfo: Added rdd_10_0 in memory on 192.168.0.22:49386 (size: 464.0 B, free: 366.3 MB)
17/09/21 23:52:22 INFO CodeGenerator: Code generated in 7.147351 ms
17/09/21 23:52:22 INFO CodeGenerator: Code generated in 20.292052 ms
17/09/21 23:52:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2750 bytes result sent to driver
17/09/21 23:52:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 183 ms on localhost (executor driver) (1/1)
17/09/21 23:52:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/09/21 23:52:22 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 0.184 s
17/09/21 23:52:22 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:52:22 INFO DAGScheduler: running: Set()
17/09/21 23:52:22 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/09/21 23:52:22 INFO DAGScheduler: failed: Set()
17/09/21 23:52:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/09/21 23:52:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:52:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:52:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.0.22:49386 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:52:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/09/21 23:52:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/09/21 23:52:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/09/21 23:52:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 6392 bytes)
17/09/21 23:52:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/09/21 23:52:22 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:52:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/09/21 23:52:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2042 bytes result sent to driver
17/09/21 23:52:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1)
17/09/21 23:52:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/09/21 23:52:22 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.030 s
17/09/21 23:52:22 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.250630 s
17/09/21 23:52:22 INFO CodeGenerator: Code generated in 10.260742 ms
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 52
17/09/21 23:52:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.0.22:49386 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 53
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 54
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 55
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 56
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 57
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 58
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 59
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 60
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 61
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 62
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 63
17/09/21 23:52:24 INFO ContextCleaner: Cleaned accumulator 64
17/09/21 23:52:24 INFO ContextCleaner: Cleaned shuffle 0
17/09/21 23:52:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.0.22:49386 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:52:24 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `df`
17/09/21 23:52:25 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:52:25 INFO DAGScheduler: Registering RDD 20 (collect at <console>:224)
17/09/21 23:52:25 INFO DAGScheduler: Got job 2 (collect at <console>:224) with 1 output partitions
17/09/21 23:52:25 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <console>:224)
17/09/21 23:52:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/09/21 23:52:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/09/21 23:52:25 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224), which has no missing parents
17/09/21 23:52:25 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.3 KB, free 366.3 MB)
17/09/21 23:52:25 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KB, free 366.3 MB)
17/09/21 23:52:25 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.0.22:49386 (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:52:25 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/09/21 23:52:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at <console>:224)
17/09/21 23:52:25 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/21 23:52:25 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6696 bytes)
17/09/21 23:52:25 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/21 23:52:25 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:52:25 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2101 bytes result sent to driver
17/09/21 23:52:25 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 16 ms on localhost (executor driver) (1/1)
17/09/21 23:52:25 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/09/21 23:52:25 INFO DAGScheduler: ShuffleMapStage 3 (collect at <console>:224) finished in 0.016 s
17/09/21 23:52:25 INFO DAGScheduler: looking for newly runnable stages
17/09/21 23:52:25 INFO DAGScheduler: running: Set()
17/09/21 23:52:25 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/09/21 23:52:25 INFO DAGScheduler: failed: Set()
17/09/21 23:52:25 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224), which has no missing parents
17/09/21 23:52:25 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 7.0 KB, free 366.3 MB)
17/09/21 23:52:25 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.7 KB, free 366.3 MB)
17/09/21 23:52:25 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.0.22:49386 (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:52:25 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/09/21 23:52:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at <console>:224)
17/09/21 23:52:25 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/09/21 23:52:25 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, ANY, 6384 bytes)
17/09/21 23:52:25 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/21 23:52:25 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/09/21 23:52:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/21 23:52:25 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 2042 bytes result sent to driver
17/09/21 23:52:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 6 ms on localhost (executor driver) (1/1)
17/09/21 23:52:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/09/21 23:52:25 INFO DAGScheduler: ResultStage 4 (collect at <console>:224) finished in 0.006 s
17/09/21 23:52:25 INFO DAGScheduler: Job 2 finished: collect at <console>:224, took 0.035106 s
17/09/21 23:52:26 INFO ContextCleaner: Cleaned accumulator 161
17/09/21 23:52:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df` AS `zzz432`
WHERE (0 = 1)
17/09/21 23:52:26 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 192.168.0.22:49386 in memory (size: 3.7 KB, free: 366.3 MB)
17/09/21 23:52:26 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.0.22:49386 in memory (size: 7.6 KB, free: 366.3 MB)
17/09/21 23:52:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `df`
17/09/21 23:52:29 INFO SparkContext: Starting job: collect at <console>:224
17/09/21 23:52:29 INFO DAGScheduler: Got job 3 (collect at <console>:224) with 1 output partitions
17/09/21 23:52:29 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <console>:224)
17/09/21 23:52:29 INFO DAGScheduler: Parents of final stage: List()
17/09/21 23:52:29 INFO DAGScheduler: Missing parents: List()
17/09/21 23:52:29 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224), which has no missing parents
17/09/21 23:52:29 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.0 KB, free 366.3 MB)
17/09/21 23:52:29 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.7 KB, free 366.3 MB)
17/09/21 23:52:29 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.0.22:49386 (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:52:29 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/09/21 23:52:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[25] at collect at <console>:224)
17/09/21 23:52:29 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/21 23:52:29 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6707 bytes)
17/09/21 23:52:29 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/09/21 23:52:29 INFO BlockManager: Found block rdd_10_0 locally
17/09/21 23:52:29 INFO CodeGenerator: Code generated in 19.807976 ms
17/09/21 23:52:29 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1608 bytes result sent to driver
17/09/21 23:52:29 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 35 ms on localhost (executor driver) (1/1)
17/09/21 23:52:29 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/09/21 23:52:29 INFO DAGScheduler: ResultStage 5 (collect at <console>:224) finished in 0.036 s
17/09/21 23:52:29 INFO DAGScheduler: Job 3 finished: collect at <console>:224, took 0.041646 s
17/09/21 23:52:29 INFO CodeGenerator: Code generated in 8.714967 ms
17/09/21 23:52:30 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.0.22:49386 in memory (size: 5.7 KB, free: 366.3 MB)
17/09/21 23:52:30 INFO SparkUI: Stopped Spark web UI at http://192.168.0.22:4040
17/09/21 23:52:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:52:30 INFO MemoryStore: MemoryStore cleared
17/09/21 23:52:30 INFO BlockManager: BlockManager stopped
17/09/21 23:52:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:52:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:52:30 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:52:30 INFO SparkContext: SparkContext already stopped.
17/09/21 23:52:30 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:52:30 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-8c8f1710-27a5-41e7-ade0-440f62ee524e
17/09/21 23:58:22 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:58:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:58:23 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:58:23 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:58:23 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:58:23 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:58:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:58:23 INFO Utils: Successfully started service 'sparkDriver' on port 49987.
17/09/21 23:58:23 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:58:23 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:58:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:58:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:58:23 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-4ca849d3-4c89-4354-bd1d-1de8d26a458f
17/09/21 23:58:23 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:58:23 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:58:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/09/21 23:58:23 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/09/21 23:58:23 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/09/21 23:58:23 INFO SparkContext: Added JAR file:/Users/javierluraschi/RStudio/sparklyr/inst/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:49987/jars/sparklyr-2.1-2.11.jar with timestamp 1506063503514
17/09/21 23:58:23 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:58:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49988.
17/09/21 23:58:23 INFO NettyBlockTransferService: Server created on 127.0.0.1:49988
17/09/21 23:58:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:58:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49988, None)
17/09/21 23:58:23 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49988 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49988, None)
17/09/21 23:58:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49988, None)
17/09/21 23:58:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49988, None)
17/09/21 23:58:23 INFO SparkContext: Invoking stop() from shutdown hook
17/09/21 23:58:23 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/09/21 23:58:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/21 23:58:23 INFO MemoryStore: MemoryStore cleared
17/09/21 23:58:23 INFO BlockManager: BlockManager stopped
17/09/21 23:58:23 INFO BlockManagerMaster: BlockManagerMaster stopped
17/09/21 23:58:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/21 23:58:23 INFO SparkContext: Successfully stopped SparkContext
17/09/21 23:58:23 INFO ShutdownHookManager: Shutdown hook called
17/09/21 23:58:23 INFO ShutdownHookManager: Deleting directory /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/spark-79aa0a99-e8f1-4d6f-bfbf-ab5eba5d4eea
17/09/21 23:59:21 INFO RSCDriver: Connecting to: 192.168.0.22:50122
17/09/21 23:59:21 INFO RSCDriver: Starting RPC server...
17/09/21 23:59:26 WARN RSCConf: Your hostname, 192.168.0.22, resolves to a loopback address, but we couldn't find any external IP address!
17/09/21 23:59:26 WARN RSCConf: Set livy.rsc.rpc.server.address if you need to bind to another address.
17/09/21 23:59:26 INFO RSCDriver: Received job request 8ab50868-3100-423d-92bf-e7df576786c7
17/09/21 23:59:26 INFO RSCDriver: SparkContext not yet up, queueing job request.
17/09/21 23:59:28 INFO SparkContext: Running Spark version 2.1.0
17/09/21 23:59:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/21 23:59:34 INFO SecurityManager: Changing view acls to: javierluraschi
17/09/21 23:59:34 INFO SecurityManager: Changing modify acls to: javierluraschi
17/09/21 23:59:34 INFO SecurityManager: Changing view acls groups to: 
17/09/21 23:59:34 INFO SecurityManager: Changing modify acls groups to: 
17/09/21 23:59:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(javierluraschi); groups with view permissions: Set(); users  with modify permissions: Set(javierluraschi); groups with modify permissions: Set()
17/09/21 23:59:34 INFO Utils: Successfully started service 'sparkDriver' on port 50129.
17/09/21 23:59:34 INFO SparkEnv: Registering MapOutputTracker
17/09/21 23:59:34 INFO SparkEnv: Registering BlockManagerMaster
17/09/21 23:59:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/09/21 23:59:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/09/21 23:59:34 INFO DiskBlockManager: Created local directory at /private/var/folders/fz/v6wfsg2x1fb1rw4f6r0x4jwm0000gn/T/blockmgr-fb3a920b-a38b-4e79-a30a-066d097cc2b2
17/09/21 23:59:34 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/09/21 23:59:34 INFO SparkEnv: Registering OutputCommitCoordinator
17/09/21 23:59:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/09/21 23:59:34 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.0.22:4040
17/09/21 23:59:34 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-api-0.3.0.jar at spark://192.168.0.22:50129/jars/livy-api-0.3.0.jar with timestamp 1506063574688
17/09/21 23:59:34 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/livy-rsc-0.3.0.jar at spark://192.168.0.22:50129/jars/livy-rsc-0.3.0.jar with timestamp 1506063574688
17/09/21 23:59:34 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/rsc-jars/netty-all-4.0.29.Final.jar at spark://192.168.0.22:50129/jars/netty-all-4.0.29.Final.jar with timestamp 1506063574688
17/09/21 23:59:34 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/commons-codec-1.9.jar at spark://192.168.0.22:50129/jars/commons-codec-1.9.jar with timestamp 1506063574689
17/09/21 23:59:34 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-core_2.11-0.3.0.jar at spark://192.168.0.22:50129/jars/livy-core_2.11-0.3.0.jar with timestamp 1506063574689
17/09/21 23:59:34 INFO SparkContext: Added JAR file:/Users/javierluraschi/Library/Caches/livy/livy-0.3.0/repl_2.11-jars/livy-repl_2.11-0.3.0.jar at spark://192.168.0.22:50129/jars/livy-repl_2.11-0.3.0.jar with timestamp 1506063574689
17/09/21 23:59:34 INFO Executor: Starting executor ID driver on host localhost
17/09/21 23:59:34 INFO Executor: Using REPL class URI: spark://192.168.0.22:50129/classes
17/09/21 23:59:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50131.
17/09/21 23:59:34 INFO NettyBlockTransferService: Server created on 192.168.0.22:50131
17/09/21 23:59:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/09/21 23:59:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.0.22, 50131, None)
17/09/21 23:59:34 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.0.22:50131 with 366.3 MB RAM, BlockManagerId(driver, 192.168.0.22, 50131, None)
17/09/21 23:59:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.0.22, 50131, None)
17/09/21 23:59:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.0.22, 50131, None)
17/09/21 23:59:34 INFO SharedState: Warehouse path is 'file:/Users/javierluraschi/RStudio/sparklyr/tests/testthat/spark-warehouse/'.
17/09/21 23:59:35 INFO SparkInterpreter: Created Spark session.
